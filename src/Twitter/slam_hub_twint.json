{"id": 1289395689697337344, "conversation_id": "1289395426723016708", "created_at": 1596250862000, "date": "2020-08-01", "time": "03:01:02", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "PointContrast: Unsupervised Pre-training for 3D Point Cloud Understanding (ECCV2020)\nPaper:  https://arxiv.org/abs/2007.10985 ", "mentions": [], "urls": ["https://arxiv.org/abs/2007.10985"], "photos": [], "replies_count": 0, "retweets_count": 2, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1289395689697337344", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1289395426723016708, "conversation_id": "1289395426723016708", "created_at": 1596250800000, "date": "2020-08-01", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "点群データに対する教師なしの事前学習手法を提案．ScanNetから抽出した視点の異なる2つの点群に対し，点のマッチングを基に距離学習を行う．事前学習済みモデルを転移することで屋内外を含む6種の広範なデータセットで精度向上が得られた． https://arxiv.org/abs/2007.10985  pic.twitter.com/gEDAQZD95r", "mentions": [], "urls": ["https://arxiv.org/abs/2007.10985"], "photos": ["https://pbs.twimg.com/media/EePiWZ2VAAY4Wok.png"], "replies_count": 1, "retweets_count": 3, "likes_count": 23, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1289395426723016708", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1289206810314862593, "conversation_id": "1289191063937196036", "created_at": 1596205830000, "date": "2020-07-31", "time": "14:30:30", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "@ossyaritoori ご連絡ありがとうございます．とても面白い記事ですね．転載されているのは僅かでしたしご連絡頂いたので問題ございません．今後も更新していくので引き続きご覧頂けますと幸いです．", "mentions": ["ossyaritoori"], "urls": [], "photos": [], "replies_count": 1, "retweets_count": 0, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1289206810314862593", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}, {"user_id": "543648159", "username": "ossyaritoori"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1289033252682924034, "conversation_id": "1289033039637557249", "created_at": 1596164451000, "date": "2020-07-31", "time": "03:00:51", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Neural Topological SLAM for Visual Navigation, CVPR2020\nProject:  https://www.cs.cmu.edu/~dchaplot/projects/neural-topological-slam.html … pic.twitter.com/CVya3XyiuY", "mentions": [], "urls": ["https://www.cs.cmu.edu/~dchaplot/projects/neural-topological-slam.html"], "photos": [], "replies_count": 0, "retweets_count": 3, "likes_count": 5, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1289033252682924034", "retweet": false, "quote_url": "", "video": 1, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1289033039637557249, "conversation_id": "1289033039637557249", "created_at": 1596164400000, "date": "2020-07-31", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "目標画像位置を未知環境内で探すトポロジカルグラフSLAM＋探索手法を提案．各地点(ノード)での周囲の移動可能領域・目的地到達可能性を教師あり学習し，それをもとにグラフ上で探索行動を生成する．強化・教師なし学習ベース手法と比較し安定した学習・高精度な探索を実現． https://youtu.be/vubX97owdjQ ", "mentions": [], "urls": ["https://youtu.be/vubX97owdjQ"], "photos": [], "replies_count": 1, "retweets_count": 6, "likes_count": 17, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1289033039637557249", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1288666571095842818, "conversation_id": "1288666567933190144", "created_at": 1596077027000, "date": "2020-07-30", "time": "02:43:47", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Points2Surf：Learning Implicit Surfaces from Point Clouds (ECCV2020)\nPaper:  https://arxiv.org/abs/2007.10453 \nProject:  https://www.cg.tuwien.ac.at/research/publications/2020/erler-p2s/ …\nCode:  https://github.com/ErlerPhilipp/points2surf …", "mentions": [], "urls": ["https://arxiv.org/abs/2007.10453", "https://www.cg.tuwien.ac.at/research/publications/2020/erler-p2s/", "https://github.com/ErlerPhilipp/points2surf"], "photos": [], "replies_count": 0, "retweets_count": 2, "likes_count": 6, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1288666571095842818", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1288666567933190144, "conversation_id": "1288666567933190144", "created_at": 1596077026000, "date": "2020-07-30", "time": "02:43:46", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "ノイズや不均一な点群から物体のimplicit表面の推定手法を提案。クエリ点に対する点群のGlobalとLocal情報から、sign logitとabsolute distanceを別々に推定するネットワークを学習させ、signed distance field (SDF)を得て、TSDF へ変換、Marching Cubesで表面を生成する。\n https://arxiv.org/abs/2007.10453  pic.twitter.com/bWgcYMUvDy", "mentions": [], "urls": ["https://arxiv.org/abs/2007.10453"], "photos": ["https://pbs.twimg.com/media/EeJDOz5U8AE98jX.jpg"], "replies_count": 1, "retweets_count": 7, "likes_count": 32, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1288666567933190144", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1288308338145411073, "conversation_id": "1288308266947272704", "created_at": 1595991618000, "date": "2020-07-29", "time": "03:00:18", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "DeepCap: Monocular Human Performance Capture Using Weak Supervision (CVPR2020)\nPaper:  https://arxiv.org/abs/2003.08325 \nProject:  https://people.mpi-inf.mpg.de/~mhaberma/projects/2020-cvpr-deepcap/ …\nVideo: https://www.youtube.com/watch?v=C4eDrvJ9aBs …", "mentions": [], "urls": ["https://arxiv.org/abs/2003.08325", "https://people.mpi-inf.mpg.de/~mhaberma/projects/2020-cvpr-deepcap/", "https://www.youtube.com/watch?v=C4eDrvJ9aBs"], "photos": [], "replies_count": 0, "retweets_count": 2, "likes_count": 6, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1288308338145411073", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1288308266947272704, "conversation_id": "1288308266947272704", "created_at": 1595991601000, "date": "2020-07-29", "time": "03:00:01", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "単一の画像からの衣服を含む人体形状復元．PoseNetによる関節位置の推定とDefNetによる表面形状の変形推定を組み合わせたロス関数を設計し学習．単一画像のみから，多視点画像を利用する従来手法と競合する復元精度を実現している．\n https://arxiv.org/abs/2003.08325  pic.twitter.com/hH7pC6l1xs", "mentions": [], "urls": ["https://arxiv.org/abs/2003.08325"], "photos": ["https://pbs.twimg.com/media/EeD8ogfUMAAU5TB.jpg"], "replies_count": 1, "retweets_count": 6, "likes_count": 26, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1288308266947272704", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1287946042286026752, "conversation_id": "1287945878561361920", "created_at": 1595905240000, "date": "2020-07-28", "time": "03:00:40", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Efficient Continuous-Time SLAM for 3D Lidar-based Online Mapping (ICRA 2018)\nPaper:  https://arxiv.org/abs/1810.06802 \nPaper:  https://ieeexplore.ieee.org/document/8461000 …\nVideo: https://youtu.be/iG9MJLzja5g ", "mentions": [], "urls": ["https://arxiv.org/abs/1810.06802", "https://ieeexplore.ieee.org/document/8461000", "https://youtu.be/iG9MJLzja5g"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1287946042286026752", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1287945878561361920, "conversation_id": "1287945878561361920", "created_at": 1595905200000, "date": "2020-07-28", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "離散時間ではなく連続時間で軌跡を推定する Continuous-Time SLAM の一手法。スキャン点群のスパース（疎）性と歪みの問題に対処。Surfel を用いた位置合わせで、複数解像度の局所地図を構築。局所地図ノードとロボット位置ノードからなる階層的ポーズグラフを相互に最適化。\n https://arxiv.org/abs/1810.06802  pic.twitter.com/LpD2xCvjUM", "mentions": [], "urls": ["https://arxiv.org/abs/1810.06802"], "photos": ["https://pbs.twimg.com/media/Ed-kCY2UMAEysLQ.jpg"], "replies_count": 1, "retweets_count": 13, "likes_count": 57, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1287945878561361920", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1287584171481632770, "conversation_id": "1287584106847510528", "created_at": 1595818963000, "date": "2020-07-27", "time": "03:02:43", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual-Inertial and Multi-Map SLAM (arXiv)\nPaper:  https://arxiv.org/abs/2007.11898 \nProject:  https://github.com/UZ-SLAMLab/ORB_SLAM3 …\nVideo:  https://youtu.be/HyLNq-98LRo ", "mentions": [], "urls": ["https://arxiv.org/abs/2007.11898", "https://github.com/UZ-SLAMLab/ORB_SLAM3", "https://youtu.be/HyLNq-98LRo"], "photos": [], "replies_count": 0, "retweets_count": 2, "likes_count": 5, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1287584171481632770", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1287584106847510528, "conversation_id": "1287584106847510528", "created_at": 1595818947000, "date": "2020-07-27", "time": "03:02:27", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "ORB-SLAMの最新バージョン．ORB-SLAM2との違いはマルチマップ・システムで，過去マップに対する自己位置同定だけではなく，自己位置ロスト後に新しいマップを生成し，Place Recognition成功後に過去マップと統合しロバスト性を向上．従来法にくらべ数倍の精度向上を達成． https://youtu.be/HyLNq-98LRo ", "mentions": [], "urls": ["https://youtu.be/HyLNq-98LRo"], "photos": [], "replies_count": 1, "retweets_count": 20, "likes_count": 64, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1287584106847510528", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1287351688802705408, "conversation_id": "1287351687296892928", "created_at": 1595763535000, "date": "2020-07-26", "time": "11:38:55", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Privacy Preserving Structure-from-Motion (ECCV2020)\nProject:  https://cvg.ethz.ch/research/privacy-preserving-sfm …\nSupp:  https://cvg.ethz.ch/research/privacy-preserving-sfm/paper/Geppert2020ECCV_supp.pdf …\nVideo:  https://cvg.ethz.ch/research/privacy-preserving-sfm/paper/Geppert2020ECCV_supp_video.mp4 … pic.twitter.com/ATTcyyT1PB", "mentions": [], "urls": ["https://cvg.ethz.ch/research/privacy-preserving-sfm", "https://cvg.ethz.ch/research/privacy-preserving-sfm/paper/Geppert2020ECCV_supp.pdf", "https://cvg.ethz.ch/research/privacy-preserving-sfm/paper/Geppert2020ECCV_supp_video.mp4"], "photos": ["https://pbs.twimg.com/media/Ed2Xc1yVoAYCXKC.png"], "replies_count": 0, "retweets_count": 1, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1287351688802705408", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1287351687296892928, "conversation_id": "1287351687296892928", "created_at": 1595763534000, "date": "2020-07-26", "time": "11:38:54", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "This paper proposes an incremental SfM system with privacy protection. The system uses only random 2D lines converted from 2D feature points for its initialization, camera pose estimation, triangulation, and bundle adjustment. \n https://www.cvg.ethz.ch/research/privacy-preserving-sfm/paper/Geppert2020ECCV.pdf … pic.twitter.com/n9XrXyM4K5", "mentions": [], "urls": ["https://www.cvg.ethz.ch/research/privacy-preserving-sfm/paper/Geppert2020ECCV.pdf"], "photos": ["https://pbs.twimg.com/media/Ed2XW4DUcAImzDU.png"], "replies_count": 1, "retweets_count": 3, "likes_count": 13, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1287351687296892928", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1287253430667341824, "conversation_id": "1287253428670853121", "created_at": 1595740108000, "date": "2020-07-26", "time": "05:08:28", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Privacy Preserving Structure-from-Motion (ECCV2020)\nProject:  https://www.cvg.ethz.ch/research/privacy-preserving-sfm …\nSupp:  https://www.cvg.ethz.ch/research/privacy-preserving-sfm/paper/Geppert2020ECCV_supp.pdf …\nVideo:  https://www.cvg.ethz.ch/research/privacy-preserving-sfm/paper/Geppert2020ECCV_supp_video.mp4 … pic.twitter.com/hxSGXSJnfV", "mentions": [], "urls": ["https://www.cvg.ethz.ch/research/privacy-preserving-sfm", "https://www.cvg.ethz.ch/research/privacy-preserving-sfm/paper/Geppert2020ECCV_supp.pdf", "https://www.cvg.ethz.ch/research/privacy-preserving-sfm/paper/Geppert2020ECCV_supp_video.mp4"], "photos": ["https://pbs.twimg.com/media/Ed0-JnEUYAAs4II.png"], "replies_count": 0, "retweets_count": 1, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1287253430667341824", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1287253428670853121, "conversation_id": "1287253428670853121", "created_at": 1595740108000, "date": "2020-07-26", "time": "05:08:28", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "プライバシー保護を考慮したIncremental SfMシステムを開発．2D特徴点から変換された2D直線のみを用いた，初期化，カメラ姿勢の推定，三角測量，バンドル調整を提案．2D特徴点を利用したSfMに近い精度と，Inverstion Attackに対するより高い頑健性を実現．\n https://www.cvg.ethz.ch/research/privacy-preserving-sfm/paper/Geppert2020ECCV.pdf … pic.twitter.com/bzFGa7QKLZ", "mentions": [], "urls": ["https://www.cvg.ethz.ch/research/privacy-preserving-sfm/paper/Geppert2020ECCV.pdf"], "photos": ["https://pbs.twimg.com/media/Ed09_7TU8Ag68FG.png"], "replies_count": 1, "retweets_count": 10, "likes_count": 38, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1287253428670853121", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1286863043696058368, "conversation_id": "1286862906143854593", "created_at": 1595647033000, "date": "2020-07-25", "time": "03:17:13", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Exploit Clues from Views: Self-Supervised and Regularized Learning for Multiview Object Recognition （CVPR2020）\nPaper:  https://arxiv.org/abs/2003.12735 \nProject:  https://chihhuiho.github.io/vispe_web/ \nCode:  https://github.com/chihhuiho/VISPE  pic.twitter.com/fbdVoPxoKS", "mentions": [], "urls": ["https://arxiv.org/abs/2003.12735", "https://chihhuiho.github.io/vispe_web/", "https://github.com/chihhuiho/VISPE"], "photos": ["https://pbs.twimg.com/media/EdvbGKhUMAEhLsx.png"], "replies_count": 0, "retweets_count": 1, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1286863043696058368", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1286862906143854593, "conversation_id": "1286862906143854593", "created_at": 1595647000000, "date": "2020-07-25", "time": "03:16:40", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "多視点物体認識のための特徴量抽出を自己教師あり学習する手法を提案．代理タスクとして，オブジェクトクラス分類を通し距離学習を行う．これにより視点に因らず同一オブジェクトならば埋め込み表現上でクラスターを形成．ダウンストリームタスクで他手法より高い精度を達成．\n https://arxiv.org/abs/2003.12735  pic.twitter.com/YyvMehYHKd", "mentions": [], "urls": ["https://arxiv.org/abs/2003.12735"], "photos": ["https://pbs.twimg.com/media/Edva-6wU8AUplEB.png"], "replies_count": 1, "retweets_count": 3, "likes_count": 20, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1286862906143854593", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1286520001906712576, "conversation_id": "1286520000627372032", "created_at": 1595565245000, "date": "2020-07-24", "time": "04:34:05", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Leveraging Stereo-Camera Data for Real-Time Dynamic Obstacle Detection and Tracking (IROS 2020)\nPaper:  https://arxiv.org/abs/2007.10743  pic.twitter.com/tgcsuZcnpm", "mentions": [], "urls": ["https://arxiv.org/abs/2007.10743"], "photos": ["https://pbs.twimg.com/media/EdqjAj8UMAEHJVl.png"], "replies_count": 0, "retweets_count": 3, "likes_count": 7, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1286520001906712576", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1286520000627372032, "conversation_id": "1286520000627372032", "created_at": 1595565245000, "date": "2020-07-24", "time": "04:34:05", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "ステレオカメラの情報から動的な障害を検出，追跡するシステムの提案．ロボット周囲の物体について動的・静的の2クラスに分類．さらに動的な物体については人とそれ以外のクラスに分類する．ノイズの多いデータから高い精度の動的物体の検出,追跡が可能なことを実験で確認． https://youtu.be/AYjgeaQR8uQ ", "mentions": [], "urls": ["https://youtu.be/AYjgeaQR8uQ"], "photos": [], "replies_count": 1, "retweets_count": 3, "likes_count": 22, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1286520000627372032", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1286239396195233793, "conversation_id": "1286133936716787713", "created_at": 1595498343000, "date": "2020-07-23", "time": "09:59:03", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Thank you for your recommendation! We have already enjoyed the paper, especially for IPU, including your CVPR paper. We want to introduce them soon!", "mentions": ["ajddavison"], "urls": [], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1286239396195233793", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}, {"user_id": "1446792746", "username": "AjdDavison"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1286135276859883520, "conversation_id": "1286133936716787713", "created_at": 1595473519000, "date": "2020-07-23", "time": "03:05:19", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Visual SLAMの第一人者 Andrew J. Davison ( @AjdDavison ) 先生が描くSLAMの未来\nFutureMapping: The Computational Structure of Spatial AI Systems\nPaper:  https://arxiv.org/abs/1803.11288 ", "mentions": ["ajddavison"], "urls": ["https://arxiv.org/abs/1803.11288"], "photos": [], "replies_count": 0, "retweets_count": 4, "likes_count": 17, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1286135276859883520", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}, {"user_id": "1446792746", "username": "AjdDavison"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1286133936716787713, "conversation_id": "1286133936716787713", "created_at": 1595473200000, "date": "2020-07-23", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "SLAM （自己位置推定と地図構築）を発展させ，シーンやオブジェクトの関係性を理解する #SpatialAI の開発が進められている ．#SpatialAI を実際のアプリケーションに応用する上で必要なアルゴリズムやプロセッサ，センサの連携などについて提唱された最初の論文．\n https://arxiv.org/abs/1803.11288  pic.twitter.com/bm9sSOj5qN", "mentions": [], "urls": ["https://arxiv.org/abs/1803.11288"], "photos": ["https://pbs.twimg.com/media/EdhgCeRU0AYBeua.png"], "replies_count": 2, "retweets_count": 37, "likes_count": 123, "hashtags": ["#spatialai", "#spatialai"], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1286133936716787713", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1285773063351484417, "conversation_id": "1285771549090308096", "created_at": 1595387161000, "date": "2020-07-22", "time": "03:06:01", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "3D Packing for Self-Supervised Monocular Depth Estimation (CVPR2020)\nPaper:  https://arxiv.org/abs/1905.02693 \nCode:  https://github.com/TRI-ML/packnet-sfm …\nDataset:  https://github.com/TRI-ML/DDAD  pic.twitter.com/4avN57SBlw", "mentions": [], "urls": ["https://arxiv.org/abs/1905.02693", "https://github.com/TRI-ML/packnet-sfm", "https://github.com/TRI-ML/DDAD"], "photos": ["https://pbs.twimg.com/media/Edf7xgHU8AArojY.png"], "replies_count": 0, "retweets_count": 3, "likes_count": 10, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1285773063351484417", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1285771549090308096, "conversation_id": "1285771549090308096", "created_at": 1595386800000, "date": "2020-07-22", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "自己教師あり学習で単眼画像のデプスを推定するPackNetを提案．ピクセルをチャンネル方向に並び替えるSpace2Depthを含むPackNetにより，重要な空間情報を保持した明瞭なデプスが推定可能．既存の教師あり学習と同程度の精度を達成． https://www.youtube.com/watch?v=b62iDkLgGSI …", "mentions": [], "urls": ["https://www.youtube.com/watch?v=b62iDkLgGSI"], "photos": [], "replies_count": 1, "retweets_count": 5, "likes_count": 25, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1285771549090308096", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1285410658880643072, "conversation_id": "1285409161451380736", "created_at": 1595300757000, "date": "2020-07-21", "time": "03:05:57", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "JSENet: Joint Semantic Segmentation and Edge Detection Network for 3D Point Clouds (ECCV2020)\nPaper:  https://arxiv.org/abs/2007.06888 \nCode: https://github.com/hzykent/JSENet ", "mentions": [], "urls": ["https://arxiv.org/abs/2007.06888", "https://github.com/hzykent/JSENet"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1285410658880643072", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1285409161451380736, "conversation_id": "1285409161451380736", "created_at": 1595300400000, "date": "2020-07-21", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "3次元点群に対してセグメンテーションとクラス境界の推定を同時に行う手法を提案．相互に関連する両タスクを同時に解くだけでなく，双方の推定結果を用いてさらに精緻化を行うNNモジュールを提案．屋内データ（S3DIS）でSOTAを達成．\n https://arxiv.org/abs/2007.06888  pic.twitter.com/O52VDKG07v", "mentions": [], "urls": ["https://arxiv.org/abs/2007.06888"], "photos": ["https://pbs.twimg.com/media/EdYEOW7VAAAj2sM.png"], "replies_count": 1, "retweets_count": 7, "likes_count": 28, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1285409161451380736", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1285049890406494209, "conversation_id": "1285049816234422272", "created_at": 1595214743000, "date": "2020-07-20", "time": "03:12:23", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Free-Space Features: Global Localization in 2D Laser SLAM  Using Distance Function Maps (IROS2019)\nPaper:  https://arxiv.org/abs/1908.01863 ", "mentions": [], "urls": ["https://arxiv.org/abs/1908.01863"], "photos": [], "replies_count": 0, "retweets_count": 2, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1285049890406494209", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1285049816234422272, "conversation_id": "1285049816234422272", "created_at": 1595214725000, "date": "2020-07-20", "time": "03:12:05", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "2D SLAMにおける地図表現にSDFを導入し，計測点が存在しない空間の情報を使った局所特徴(free-space features)を提案．曲率ベースの特徴点検出と方向付き勾配ヒストグラムを使った記述子を使い，従来手法より大域位置認識が高精度に行えることを示した．\n https://arxiv.org/abs/1908.01863  pic.twitter.com/GJSmADnz12", "mentions": [], "urls": ["https://arxiv.org/abs/1908.01863"], "photos": ["https://pbs.twimg.com/media/EdVp-HCUYAIGpyK.png"], "replies_count": 1, "retweets_count": 9, "likes_count": 54, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1285049816234422272", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1284684893906038784, "conversation_id": "1284684384776462337", "created_at": 1595127721000, "date": "2020-07-19", "time": "03:02:01", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "3D-MPA: Multi Proposal Aggregation for 3D Semantic Instance Segmentation (CVPR2020)\nPaper:  https://arxiv.org/abs/2003.13867 \nProject:  https://francisengelmann.github.io/3D-MPA/  pic.twitter.com/kgBVirhajr", "mentions": [], "urls": ["https://arxiv.org/abs/2003.13867", "https://francisengelmann.github.io/3D-MPA/"], "photos": ["https://pbs.twimg.com/media/EdQeDnKU8AAiXGQ.png"], "replies_count": 0, "retweets_count": 1, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1284684893906038784", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1284684384776462337, "conversation_id": "1284684384776462337", "created_at": 1595127600000, "date": "2020-07-19", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "三次元点群の意味的な特徴とCenter VotesからCenter Proposalを生成、GCNでProposalの特徴をリファイン、Proposalの合体によるInstance SegmentationのMulti Proposal Aggregation Network(MPA)を提案。既存手法のNon-Maximum-Suppression(NMS)と比べて、MPAの優位性を確認。 https://youtu.be/ifL8yTbRFDk ", "mentions": [], "urls": ["https://youtu.be/ifL8yTbRFDk"], "photos": [], "replies_count": 1, "retweets_count": 6, "likes_count": 16, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1284684384776462337", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1284322476151848960, "conversation_id": "1284322339836985344", "created_at": 1595041314000, "date": "2020-07-18", "time": "03:01:54", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "World-Consistent Video-to-Video Synthesis (ECCV2020)\nPaper:  https://arxiv.org/abs/2007.08509 \nProject:  https://nvlabs.github.io/wc-vid2vid/ \nVideo: https://youtu.be/rlCh6-2NfSg ", "mentions": [], "urls": ["https://arxiv.org/abs/2007.08509", "https://nvlabs.github.io/wc-vid2vid/", "https://youtu.be/rlCh6-2NfSg"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1284322476151848960", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1284322339836985344, "conversation_id": "1284322339836985344", "created_at": 1595041282000, "date": "2020-07-18", "time": "03:01:22", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "大域的な一貫性を保ったvid2vid．直前の数フレームに基づきクエリ(セマンティクス画像)に対応する画像生成を行う従来法では，同じ位置に立ち戻る場合に一貫性が保証されない．提案手法では，SfMを利用して環境を逐次的に3次元復元し，その幾何をガイドとした画像生成を行う．\n https://arxiv.org/abs/2007.08509  pic.twitter.com/uaQO8g5ofF", "mentions": [], "urls": ["https://arxiv.org/abs/2007.08509"], "photos": ["https://pbs.twimg.com/media/EdLUT0hUMAIVyYt.jpg"], "replies_count": 1, "retweets_count": 1, "likes_count": 16, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1284322339836985344", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1283960053540646913, "conversation_id": "1283959611632959489", "created_at": 1594954906000, "date": "2020-07-17", "time": "03:01:46", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "関連研究\nLeGO-LOAM: Lightweight and Ground-Optimized Lidar Odometry and Mapping on Variable Terrain (IROS 2018)\nPaper:  https://ieeexplore.ieee.org/document/8594299 …\nCode:  https://github.com/RobustFieldAutonomyLab/LeGO-LOAM …\nVideo:  https://youtu.be/O3tz_ftHV48 ", "mentions": [], "urls": ["https://ieeexplore.ieee.org/document/8594299", "https://github.com/RobustFieldAutonomyLab/LeGO-LOAM", "https://youtu.be/O3tz_ftHV48"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1283960053540646913", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1283959977057480704, "conversation_id": "1283959611632959489", "created_at": 1594954888000, "date": "2020-07-17", "time": "03:01:28", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "LIO-SAM: Tightly-coupled Lidar Inertial Odometry via Smoothing and Mapping (IROS 2020)\nPaper:  https://arxiv.org/abs/2007.00258 \nCode:  https://github.com/TixiaoShan/LIO-SAM …\nVideo:  https://youtu.be/A0H8CoORZJU ", "mentions": [], "urls": ["https://arxiv.org/abs/2007.00258", "https://github.com/TixiaoShan/LIO-SAM", "https://youtu.be/A0H8CoORZJU"], "photos": [], "replies_count": 1, "retweets_count": 1, "likes_count": 5, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1283959977057480704", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1283959611632959489, "conversation_id": "1283959611632959489", "created_at": 1594954800000, "date": "2020-07-17", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "IMU preintegration で点群を歪み補正して初期推定。エッジと平面の特徴点で LIDAR オドメトリ。GTSAM（iSAM2）で全体と局所のグラフ最適化。LIDAR-IMU のタイトカップリングでリアルタイム。ループ拘束は近傍マッチング。GNSS 拘束も。最長 19 km のデータで地図構築に成功。\n https://arxiv.org/abs/2007.00258  pic.twitter.com/ALNln6fwZX", "mentions": [], "urls": ["https://arxiv.org/abs/2007.00258"], "photos": [], "replies_count": 1, "retweets_count": 32, "likes_count": 118, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1283959611632959489", "retweet": false, "quote_url": "", "video": 1, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1283601152563490819, "conversation_id": "1283601093612548099", "created_at": 1594869337000, "date": "2020-07-16", "time": "03:15:37", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Tightly-coupled Fusion of Global Positional Measurements in Optimization-based Visual-Inertial Odometry (IROS2020)\nPaper:  https://arxiv.org/abs/2003.04159 ", "mentions": [], "urls": ["https://arxiv.org/abs/2003.04159"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1283601152563490819", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1283601093612548099, "conversation_id": "1283601093612548099", "created_at": 1594869323000, "date": "2020-07-16", "time": "03:15:23", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Pre-Integration を用いた Tight-coupled な Visual-Inertial Odometry (VIO) に、GPS等によるグローバル座標拘束を導入する手法を初めて提案．従来法はVIOの後段にカルマンフィルタ等を用いて分割して対処．提案手法はコスト関数に拘束を組込み一括で最適化．\n https://arxiv.org/abs/2003.04159  pic.twitter.com/Im1bHSvCyO", "mentions": [], "urls": ["https://arxiv.org/abs/2003.04159"], "photos": ["https://pbs.twimg.com/media/EdBEUIHUcAE5_bz.png"], "replies_count": 1, "retweets_count": 4, "likes_count": 20, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1283601093612548099", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1283238520606228481, "conversation_id": "1283234833829945345", "created_at": 1594782879000, "date": "2020-07-15", "time": "03:14:39", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "著者ツイート\n@rmurai0610", "mentions": ["rmurai0610"], "urls": [], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 0, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1283238520606228481", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}, {"user_id": "1023078771073605632", "username": "rmurai0610"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1283238519532486656, "conversation_id": "1283234833829945345", "created_at": 1594782879000, "date": "2020-07-15", "time": "03:14:39", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "BIT-VO: Visual Odometry at 300 FPS using Binary Features from the Focal Plane (IROS2020)\nPaper:  https://arxiv.org/abs/2004.11186 \nProject:  https://rmurai0610.github.io/BIT-VO \nVideo:  https://www.youtube.com/watch?v=tnPfbJaPrSQ&feature=emb_title …", "mentions": [], "urls": ["https://arxiv.org/abs/2004.11186", "https://rmurai0610.github.io/BIT-VO", "https://www.youtube.com/watch?v=tnPfbJaPrSQ&feature=emb_title"], "photos": [], "replies_count": 1, "retweets_count": 1, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1283238519532486656", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1283234833829945345, "conversation_id": "1283234833829945345", "created_at": 1594782000000, "date": "2020-07-15", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "画素毎に並列計算可能なFocal-plane Sensor-processor (FPSP) を用いたVisual OdometryアルゴリズムBIT-VOを提案．FPSP上で，アナログ信号の領域で2値のエッジ検出を行い，そのエッジからバイナリ特徴を計算．それらをホストデバイスに転送することで300fpsの6DOF VOを実現． https://www.youtube.com/watch?v=tnPfbJaPrSQ&feature=emb_title …", "mentions": [], "urls": ["https://www.youtube.com/watch?v=tnPfbJaPrSQ&feature=emb_title"], "photos": [], "replies_count": 1, "retweets_count": 6, "likes_count": 29, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1283234833829945345", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1282872988400934912, "conversation_id": "1282872986467397633", "created_at": 1594695729000, "date": "2020-07-14", "time": "03:02:09", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Self-Supervised Viewpoint Learning From Image Collections (CVPR2020)\nPaper:  https://arxiv.org/abs/2004.01793 \nProject:  https://research.nvidia.com/publication/2020-03_Self-Supervised-Viewpoint-Learning …\nCode:  https://github.com/NVlabs/SSV  pic.twitter.com/9TgUW7zLPZ", "mentions": [], "urls": ["https://arxiv.org/abs/2004.01793", "https://research.nvidia.com/publication/2020-03_Self-Supervised-Viewpoint-Learning", "https://github.com/NVlabs/SSV"], "photos": ["https://pbs.twimg.com/media/Ec2uHoIUEAAgF2a.png"], "replies_count": 0, "retweets_count": 0, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1282872988400934912", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1282872986467397633, "conversation_id": "1282872986467397633", "created_at": 1594695729000, "date": "2020-07-14", "time": "03:02:09", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "画像からの物体方向推定を，self-supervisedに学習する枠組みを提案．画像から3次元方向とスタイル特徴量を抽出し，それらの潜在変数を元に幾何学的変換を行うGenerator(GAN)を用いて学習．損失には一貫性と水平対称性を利用し，教師あり学習に匹敵する性能を達成．\n https://arxiv.org/abs/2004.01793  pic.twitter.com/Qr4LM3uTxA", "mentions": [], "urls": ["https://arxiv.org/abs/2004.01793"], "photos": ["https://pbs.twimg.com/media/Ec2t_Y-UcAAYEyM.png"], "replies_count": 1, "retweets_count": 9, "likes_count": 27, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1282872986467397633", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1282511151562018816, "conversation_id": "1282510058660737024", "created_at": 1594609461000, "date": "2020-07-13", "time": "03:04:21", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "ODE-CNN: Omnidirectional Depth Extension Networks (ICRA 2020)\nPaper:  https://arxiv.org/abs/2007.01475 ", "mentions": [], "urls": ["https://arxiv.org/abs/2007.01475"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 6, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1282511151562018816", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1282510058660737024, "conversation_id": "1282510058660737024", "created_at": 1594609200000, "date": "2020-07-13", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Kinect等のPerspectiveなdepthセンサーと全方位画像を用いて全方位のdepthを得る手法の提案.Encoderの最後の層でPerspective座標に変換し特徴量の学習難度を下げ、Decoderでequirectangular座標に戻す.他のSoTAな手法より優れていることを示した.\n https://arxiv.org/abs/2007.01475  pic.twitter.com/ZYPB7ysvaY", "mentions": [], "urls": ["https://arxiv.org/abs/2007.01475"], "photos": ["https://pbs.twimg.com/media/EcuxFqyU4AAiQBT.png"], "replies_count": 1, "retweets_count": 12, "likes_count": 50, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1282510058660737024", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1282203801890373633, "conversation_id": "1282203799256350721", "created_at": 1594536183000, "date": "2020-07-12", "time": "06:43:03", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "360-Indoor: Towards Learning Real-World Objects in 360◦ Indoor Equirectangular Images (WACV2020)\nPaper: \n https://arxiv.org/abs/1910.01712 ", "mentions": [], "urls": ["https://arxiv.org/abs/1910.01712"], "photos": [], "replies_count": 0, "retweets_count": 3, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1282203801890373633", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1282203799256350721, "conversation_id": "1282203799256350721", "created_at": 1594536182000, "date": "2020-07-12", "time": "06:43:02", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "360度屋内画像における物体検出とクラス認識に関するデータセットを提示．Equirectangular形式における極領域の歪みに対応するため，Sphere Netをはじめとする球状CNNを用いたモデルで評価したところ，透視投影画像によるデータセットでの学習よりも大きな改善が見られた． https://arxiv.org/abs/1910.01712  pic.twitter.com/buiy0FHupl", "mentions": [], "urls": ["https://arxiv.org/abs/1910.01712"], "photos": ["https://pbs.twimg.com/media/EctNZZjVcAA-IRH.png"], "replies_count": 1, "retweets_count": 28, "likes_count": 77, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1282203799256350721", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1281794470577500160, "conversation_id": "1281794468920713217", "created_at": 1594438591000, "date": "2020-07-11", "time": "03:36:31", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Pseudo RGB-D for Self-Improving Monocular SLAM and Depth Prediction (ECCV2020 Poster)\nVideo1:  https://youtu.be/MffXsKjy9W0 \nVideo2:  https://youtu.be/OOPJpHexrdE \nVideo3:  https://youtu.be/PMYI9j5vHOw \nPaper:  https://arxiv.org/abs/2004.10681 ", "mentions": [], "urls": ["https://youtu.be/MffXsKjy9W0", "https://youtu.be/OOPJpHexrdE", "https://youtu.be/PMYI9j5vHOw", "https://arxiv.org/abs/2004.10681"], "photos": [], "replies_count": 0, "retweets_count": 2, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1281794470577500160", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1281794468920713217, "conversation_id": "1281794468920713217", "created_at": 1594438590000, "date": "2020-07-11", "time": "03:36:30", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "CNNで推定した擬似的なデプスマップを用いてRGB-D SLAMを行う．単眼デプス推定の欠点であるスケールの不整合性を，特徴点ベースのSLAMで作成された三次元点を用いてリファインする．これにより，両者の欠点を補った高精度な姿勢推定が可能となった．\n https://arxiv.org/abs/2004.10681  pic.twitter.com/OXOuG5onDG", "mentions": [], "urls": ["https://arxiv.org/abs/2004.10681"], "photos": ["https://pbs.twimg.com/media/EcnZCpAUEAEpnSG.png"], "replies_count": 1, "retweets_count": 12, "likes_count": 54, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1281794468920713217", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1281425754194993152, "conversation_id": "1281422893826494464", "created_at": 1594350682000, "date": "2020-07-10", "time": "03:11:22", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "FPConv: Learning Local Flattening for Point Convolution (CVPR2020)\nPaper:  https://arxiv.org/abs/2002.10701 \nRelated work:  https://arxiv.org/abs/1807.02443 \nCode: https://github.com/lyqun/FPConv ", "mentions": [], "urls": ["https://arxiv.org/abs/2002.10701", "https://arxiv.org/abs/1807.02443", "https://github.com/lyqun/FPConv"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1281425754194993152", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1281422893826494464, "conversation_id": "1281422893826494464", "created_at": 1594350000000, "date": "2020-07-10", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "平面への投影を用いた点群畳み込みを提案．明示的に接平面を推定するTangentConvとは異なり，点群の投影と内挿を単一の重み行列で表現し，MLPを用いて学習ベースで推定する．Volmetricな畳み込みとの組み合わせでSoTA達成．\n https://arxiv.org/abs/2002.10701  pic.twitter.com/ZmJ3UuwIg1", "mentions": [], "urls": ["https://arxiv.org/abs/2002.10701"], "photos": ["https://pbs.twimg.com/media/EceUhQ5VAAEEjKk.jpg"], "replies_count": 1, "retweets_count": 8, "likes_count": 26, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1281422893826494464", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1281074929438343168, "conversation_id": "1281074772625874946", "created_at": 1594267039000, "date": "2020-07-09", "time": "03:57:19", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "1-Day Learning, 1-Year Localization: Long-Term LiDAR Localization Using Scan Context Image (RA-L/ICRA2019)\nPaper:  https://ieeexplore.ieee.org/abstract/document/8633942 …\nCode: https://github.com/irapkaist/scancontext …", "mentions": [], "urls": ["https://ieeexplore.ieee.org/abstract/document/8633942", "https://github.com/irapkaist/scancontext"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1281074929438343168", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1281074772625874946, "conversation_id": "1281074772625874946", "created_at": 1594267001000, "date": "2020-07-09", "time": "03:56:41", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "LIDARを使った位置推定手法．極座標で作られた高さマップ(Scan Context)を入力とし，CNNで地図上での位置をクラスとして推定する．複数の実データセット上で，一日の学習データで一年通した長期位置推定が高精度に可能であることを示した． https://youtu.be/apmmduXTnaE ", "mentions": [], "urls": ["https://youtu.be/apmmduXTnaE"], "photos": [], "replies_count": 1, "retweets_count": 3, "likes_count": 21, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1281074772625874946", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1280724053129486336, "conversation_id": "1280724052026392576", "created_at": 1594183383000, "date": "2020-07-08", "time": "04:43:03", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "BSP-Net: Generating Compact Meshes via Binary Space Partitioning (CVPR2020 Best Student Paper)\nPaper:  https://arxiv.org/abs/1911.06971 \nProject:  https://bsp-net.github.io/ \nCode:  https://github.com/czq142857/BSP-NET-original … pic.twitter.com/G9DKBtwEnm", "mentions": [], "urls": ["https://arxiv.org/abs/1911.06971", "https://bsp-net.github.io/", "https://github.com/czq142857/BSP-NET-original"], "photos": ["https://pbs.twimg.com/media/EcYLq0PUYAEV8aE.jpg"], "replies_count": 0, "retweets_count": 0, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1280724053129486336", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1280724052026392576, "conversation_id": "1280724052026392576", "created_at": 1594183383000, "date": "2020-07-08", "time": "04:43:03", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "教師なしでコンパクトかつウォータータイトな三次元メッシュ生成手法を提案。Binary Space Partitioning (BSP) で再帰的に入力形状を超平面に分解し、Constructive Solid Geometry (CSG) のブーリアン演算で、分解した超平面から複雑な表面やオブジェクトの生成が可能となる。 https://youtu.be/9-ixexpjN-8 ", "mentions": [], "urls": ["https://youtu.be/9-ixexpjN-8"], "photos": [], "replies_count": 1, "retweets_count": 7, "likes_count": 19, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1280724052026392576", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1280345414881775618, "conversation_id": "1280345060442288129", "created_at": 1594093109000, "date": "2020-07-07", "time": "03:38:29", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Volumetric Instance-Aware Semantic Mapping and 3D Object Discovery (RA-L2019)\nPaper:  https://arxiv.org/abs/1903.00268 \nCode:  https://github.com/ethz-asl/voxblox-plusplus …\nVideo:  https://youtu.be/Jvl42VJmYxg  pic.twitter.com/CiR0JzN43I", "mentions": [], "urls": ["https://arxiv.org/abs/1903.00268", "https://github.com/ethz-asl/voxblox-plusplus", "https://youtu.be/Jvl42VJmYxg"], "photos": ["https://pbs.twimg.com/media/EcSzWMPU8AAhhcb.jpg"], "replies_count": 0, "retweets_count": 1, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1280345414881775618", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1280345060442288129, "conversation_id": "1280345060442288129", "created_at": 1594093024000, "date": "2020-07-07", "time": "03:37:04", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "インスタンスを意識したRGB-Dセンサによる地図生成．幾何的なセグメンテーション結果をMask R-CNNから補正し，Over-segmentationを抑制した個別の物体形状を獲得．各物体の幾何を大域地図上で関連付けていくことで，セマンティクス＆インスタンス情報も付与した地図を生成． https://youtu.be/Jvl42VJmYxg ", "mentions": [], "urls": ["https://youtu.be/Jvl42VJmYxg"], "photos": [], "replies_count": 1, "retweets_count": 7, "likes_count": 16, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1280345060442288129", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1279973645008334848, "conversation_id": "1279973343249281025", "created_at": 1594004472000, "date": "2020-07-06", "time": "03:01:12", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Visual-Inertial Mapping with Non-Linear Factor Recovery (RA-L & ICRA 2020)\nPaper:  https://arxiv.org/abs/1904.06504 \nProject:  https://vision.in.tum.de/research/vslam/basalt …\nCode:  https://gitlab.com/VladyslavUsenko/basalt …\nVideo:  https://youtu.be/r3CJ2JP75Tc ", "mentions": [], "urls": ["https://arxiv.org/abs/1904.06504", "https://vision.in.tum.de/research/vslam/basalt", "https://gitlab.com/VladyslavUsenko/basalt", "https://youtu.be/r3CJ2JP75Tc"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1279973645008334848", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1279973343249281025, "conversation_id": "1279973343249281025", "created_at": 1594004400000, "date": "2020-07-06", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Visual-Inertial SLAM の Basalt。IMU の preintegration ではなく、非線形因子復元を行って大域的に最適化。IMU の積分は誤差が大きい問題に対処。VIO の相対位置拘束とロール・ピッチ拘束、バンドル調整のループ拘束を統合。小さな最適化問題として定式化でき、精度も向上。\n https://arxiv.org/abs/1904.06504  pic.twitter.com/mQYfoQ4yjd", "mentions": [], "urls": ["https://arxiv.org/abs/1904.06504"], "photos": ["https://pbs.twimg.com/media/EcNbQNwVcAEqhUL.jpg"], "replies_count": 1, "retweets_count": 9, "likes_count": 31, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1279973343249281025", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1279611053924466688, "conversation_id": "1279610956172017666", "created_at": 1593918023000, "date": "2020-07-05", "time": "03:00:23", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "2D Laser SLAM With General Features Represented by Implicit Functions (RA-L2020)\nPaper:  https://ieeexplore.ieee.org/document/9099049 …", "mentions": [], "urls": ["https://ieeexplore.ieee.org/document/9099049"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1279611053924466688", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1279610956172017666, "conversation_id": "1279610956172017666", "created_at": 1593918000000, "date": "2020-07-05", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "任意の環境形状を表せる陰関数表現を用い2D SLAMを定式化．陰関数に対する分散の導出や陰関数境界内外での最適化の安定化などを行い，楕円・直線モデルを用いた評価実験では従来のモデルフィッティングベース手法より良い精度を示した．\n https://ieeexplore.ieee.org/document/9099049 … pic.twitter.com/HnpTxH7bL6", "mentions": [], "urls": ["https://ieeexplore.ieee.org/document/9099049"], "photos": ["https://pbs.twimg.com/media/EcIUVnyUwAARQnd.jpg"], "replies_count": 1, "retweets_count": 5, "likes_count": 23, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1279610956172017666", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1279258988664635394, "conversation_id": "1279258907534213121", "created_at": 1593834085000, "date": "2020-07-04", "time": "03:41:25", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Statistical Outlier Identification in Multi-robot Visual SLAM using Expectation Maximization\nPaper:  https://arxiv.org/abs/2002.02638 ", "mentions": [], "urls": ["https://arxiv.org/abs/2002.02638"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1279258988664635394", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1279258907534213121, "conversation_id": "1279258907534213121", "created_at": 1593834065000, "date": "2020-07-04", "time": "03:41:05", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "複数マップ間のループ検出における外れ値検出手法を提案．各ノード間の回転から閉ループの幾何的整合性をチェックすることで確率的に外れ値を検出．さらにEMアルゴリズムを用いてパラメータをfine-tune．確率伝搬法より高い精度を達成し，収束性も保証．\n https://arxiv.org/abs/2002.02638  pic.twitter.com/zugcqk2JzE", "mentions": [], "urls": ["https://arxiv.org/abs/2002.02638"], "photos": ["https://pbs.twimg.com/media/EcDXJCJUcAEXBxP.jpg"], "replies_count": 1, "retweets_count": 8, "likes_count": 23, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1279258907534213121", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278904690546098176, "conversation_id": "1278904690546098176", "created_at": 1593749613000, "date": "2020-07-03", "time": "04:13:33", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "SLAM-Hub members got one paper accepted by #ECCV2020 !", "mentions": [], "urls": [], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 9, "hashtags": ["#eccv2020"], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278904690546098176", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278904428246888448, "conversation_id": "1278904428246888448", "created_at": 1593749551000, "date": "2020-07-03", "time": "04:12:31", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "コンピュータビジョン分野の国際会議ECCV2020にSLAM-Hubのメンバーから1本の論文が採択されました！", "mentions": [], "urls": [], "photos": [], "replies_count": 0, "retweets_count": 4, "likes_count": 22, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278904428246888448", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278886404580229122, "conversation_id": "1278886178670796801", "created_at": 1593745254000, "date": "2020-07-03", "time": "03:00:54", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Vid2Curve: Simultaneous Camera Motion Estimation and Thin Structure Reconstruction from an RGB Video (SIGGRAPH 2020)\nProject:  https://totoro97.github.io/projects/vid2curve/ …\nCode:  https://github.com/Totoro97/Vid2Curve …\nPaper:  https://arxiv.org/abs/2005.03372 ", "mentions": [], "urls": ["https://totoro97.github.io/projects/vid2curve/", "https://github.com/Totoro97/Vid2Curve", "https://arxiv.org/abs/2005.03372"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278886404580229122", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278886178670796801, "conversation_id": "1278886178670796801", "created_at": 1593745200000, "date": "2020-07-03", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "ワイヤーフレームや電線など細い物体に対する形状復元の手法を提案．視点の追加ごとに，点群表現のカーブとカメラポーズを新しいマッチング手法に基づき交互に最適化。また，オクルージョンを検知し誤対応を防止．カーブの各部で太さを推定することで高品質な復元が可能に． https://youtu.be/dI2FZG_txN0 ", "mentions": [], "urls": ["https://youtu.be/dI2FZG_txN0"], "photos": [], "replies_count": 1, "retweets_count": 2, "likes_count": 16, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278886178670796801", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278526411813253121, "conversation_id": "1278523792042496000", "created_at": 1593659425000, "date": "2020-07-02", "time": "03:10:25", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "3D Human Mesh Regression with Dense Correspondence\nCode:  https://github.com/zengwang430521/DecoMR …\nPaper:  https://arxiv.org/abs/2006.05734 ", "mentions": [], "urls": ["https://github.com/zengwang430521/DecoMR", "https://arxiv.org/abs/2006.05734"], "photos": [], "replies_count": 0, "retweets_count": 5, "likes_count": 7, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278526411813253121", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278523792042496000, "conversation_id": "1278523792042496000", "created_at": 1593658800000, "date": "2020-07-02", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "一枚の画像から人体の3D Meshを推定する手法.画像ピクセルと表面間の密な対応を推定し,その対応により画像空間からUV空間へ局所的な特徴が移され,位置マップに回帰される.最後にマッピング関数により3D Meshを再構成する.3D Meshベースの従来手法より優れていることを示した.\n https://arxiv.org/abs/2006.05734  pic.twitter.com/Ku422DMyAp", "mentions": [], "urls": ["https://arxiv.org/abs/2006.05734"], "photos": ["https://pbs.twimg.com/media/Eb42BPFUcAAAe1E.jpg"], "replies_count": 1, "retweets_count": 14, "likes_count": 52, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278523792042496000", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278243785235816448, "conversation_id": "1278243781104463872", "created_at": 1593592041000, "date": "2020-07-01", "time": "08:27:21", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "“Self-supervised Simultaneous Alignment and Change Detection”,\nYukuko Furukawa, Kumiko Suzuki, Ryuhei Hamaguchi, Masaki Onishi, Ken Sakurada", "mentions": [], "urls": [], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278243785235816448", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278243784141074432, "conversation_id": "1278243781104463872", "created_at": 1593592041000, "date": "2020-07-01", "time": "08:27:21", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "\"Non-overlapping RGB-D Camera Network Calibration with Monocular Visual Odometry\",\nKenji Koide, Emanuele Menegatti", "mentions": [], "urls": [], "photos": [], "replies_count": 1, "retweets_count": 0, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278243784141074432", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278243783147089920, "conversation_id": "1278243781104463872", "created_at": 1593592041000, "date": "2020-07-01", "time": "08:27:21", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "\"C*: Cross-modal Simultaneous Tracking And Rendering for 6-DoF Monocular Camera Localization Beyond Modalities\",\nShuji Oishi, Yasunori Kawamata, Masashi Yokozuka, Kenji Koide, Atsuhiko Banno, Jun Miura", "mentions": [], "urls": [], "photos": [], "replies_count": 1, "retweets_count": 0, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278243783147089920", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278243782102708224, "conversation_id": "1278243781104463872", "created_at": 1593592040000, "date": "2020-07-01", "time": "08:27:20", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "”LiTAMIN: LiDAR based Tracking And MappINg by Stabilized ICP for Geometry Approximation with Normal Distributions”,\nMasashi Yokozuka, Kenji Koide, Shuji Oishi, Atsuhiko Banno", "mentions": [], "urls": [], "photos": [], "replies_count": 1, "retweets_count": 0, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278243782102708224", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278243781104463872, "conversation_id": "1278243781104463872", "created_at": 1593592040000, "date": "2020-07-01", "time": "08:27:20", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "SLAM-Hub members got 4 papers accepted by IROS2020!", "mentions": [], "urls": [], "photos": [], "replies_count": 2, "retweets_count": 2, "likes_count": 9, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278243781104463872", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278243514950672385, "conversation_id": "1278242853508898816", "created_at": 1593591977000, "date": "2020-07-01", "time": "08:26:17", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "“Self-supervised Simultaneous Alignment and Change Detection”,\nYukuko Furukawa, Kumiko Suzuki, Ryuhei Hamaguchi, Masaki Onishi, Ken Sakurada", "mentions": [], "urls": [], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278243514950672385", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278242856235225088, "conversation_id": "1278242853508898816", "created_at": 1593591820000, "date": "2020-07-01", "time": "08:23:40", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "\"Non-overlapping RGB-D Camera Network Calibration with Monocular Visual Odometry\",\nKenji Koide, Emanuele Menegatti", "mentions": [], "urls": [], "photos": [], "replies_count": 1, "retweets_count": 0, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278242856235225088", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278242855295676417, "conversation_id": "1278242853508898816", "created_at": 1593591819000, "date": "2020-07-01", "time": "08:23:39", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "\"C*: Cross-modal Simultaneous Tracking And Rendering for 6-DoF Monocular Camera Localization Beyond Modalities\",\nShuji Oishi, Yasunori Kawamata, Masashi Yokozuka, Kenji Koide, Atsuhiko Banno, Jun Miura", "mentions": [], "urls": [], "photos": [], "replies_count": 1, "retweets_count": 0, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278242855295676417", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278242854318424074, "conversation_id": "1278242853508898816", "created_at": 1593591819000, "date": "2020-07-01", "time": "08:23:39", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "”LiTAMIN: LiDAR based Tracking And MappINg by Stabilized ICP for Geometry Approximation with Normal Distributions”,\nMasashi Yokozuka, Kenji Koide, Shuji Oishi, Atsuhiko Banno", "mentions": [], "urls": [], "photos": [], "replies_count": 1, "retweets_count": 0, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278242854318424074", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278242853508898816, "conversation_id": "1278242853508898816", "created_at": 1593591819000, "date": "2020-07-01", "time": "08:23:39", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "ロボティクス分野の国際会議IROS2020にSLAM-Hubのメンバーから4本の論文が採択されました！", "mentions": [], "urls": [], "photos": [], "replies_count": 1, "retweets_count": 7, "likes_count": 50, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278242853508898816", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278188129539645440, "conversation_id": "1278188128444940288", "created_at": 1593578772000, "date": "2020-07-01", "time": "04:46:12", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Object-Centric Learning with Slot Attention (Under review)\nPaper :  https://arxiv.org/abs/2006.15055 ", "mentions": [], "urls": ["https://arxiv.org/abs/2006.15055"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278188129539645440", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1278188128444940288, "conversation_id": "1278188128444940288", "created_at": 1593578772000, "date": "2020-07-01", "time": "04:46:12", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "シーン分解や集合予測のアーキテクチャに統合可能な，オブジェクト中心の抽象表現を学習するSlot Attentionモジュールを提案．CNNの出力と構造表現間において，順列不変なk個のSlotを生成．反復的注意メカニズムでSlotのグループ化戦略を学習．点群やグラフのグループ化も可能 https://youtu.be/DYBmD88vpiA ", "mentions": [], "urls": ["https://youtu.be/DYBmD88vpiA"], "photos": [], "replies_count": 1, "retweets_count": 1, "likes_count": 6, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1278188128444940288", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1277799271010467842, "conversation_id": "1277799017053859842", "created_at": 1593486061000, "date": "2020-06-30", "time": "03:01:01", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "An Analysis of SVD for Deep Rotation Estimation\nPaper:  https://arxiv.org/abs/2006.14616 ", "mentions": [], "urls": ["https://arxiv.org/abs/2006.14616"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1277799271010467842", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1277799017053859842, "conversation_id": "1277799017053859842", "created_at": 1593486000000, "date": "2020-06-30", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "深層学習における性質の良い回転表現を提案．\n回転行列を一度9パラメータで表現し，SVDによる特殊直交化によりSO(3)空間へマップする．\n深層学習タスクにおいてクォータニオンやangle-axisベクトルなどの他の回転表現より高精度に姿勢を求めることが可能．\n https://arxiv.org/abs/2006.14616  pic.twitter.com/WVhQcNGBad", "mentions": [], "urls": ["https://arxiv.org/abs/2006.14616"], "photos": ["https://pbs.twimg.com/media/EbuUgMbU8AEbJUJ.jpg"], "replies_count": 1, "retweets_count": 8, "likes_count": 33, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1277799017053859842", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1277437317704069127, "conversation_id": "1277436627485290496", "created_at": 1593399764000, "date": "2020-06-29", "time": "03:02:44", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Grid-GCN for Fast and Scalable Point Cloud Learning (CVPR2020)\nPaper:  https://arxiv.org/abs/1912.02984 \nSupp:  https://xharlie.github.io/papers/GGCN_supCamReady.pdf …\nCode: https://github.com/Xharlie/Grid-GCN …", "mentions": [], "urls": ["https://arxiv.org/abs/1912.02984", "https://xharlie.github.io/papers/GGCN_supCamReady.pdf", "https://github.com/Xharlie/Grid-GCN"], "photos": [], "replies_count": 0, "retweets_count": 2, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1277437317704069127", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1277436627485290496, "conversation_id": "1277436627485290496", "created_at": 1593399600000, "date": "2020-06-29", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "高速でスケーラブルな点群データの処理機構を提案．Voxelを用いることで高速かつカバー率の高いサンプリングを行い，Voxel内部でローカルにグラフを構築して畳み込む．点群の分類とセグメンテーションで従来手法より高速かつ高精度を達成．\n https://arxiv.org/abs/1912.02984  pic.twitter.com/nlIsA1sC2v", "mentions": [], "urls": ["https://arxiv.org/abs/1912.02984"], "photos": ["https://pbs.twimg.com/media/EbpbVrhVcAM26gU.png"], "replies_count": 1, "retweets_count": 7, "likes_count": 34, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1277436627485290496", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1277074348273102848, "conversation_id": "1277074304786546689", "created_at": 1593313226000, "date": "2020-06-28", "time": "03:00:26", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "PointTriNet: Learned Triangulation of 3D Point Sets (arXiv)\nPaper:  https://arxiv.org/abs/2005.02138 ", "mentions": [], "urls": ["https://arxiv.org/abs/2005.02138"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1277074348273102848", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1277074304786546689, "conversation_id": "1277074304786546689", "created_at": 1593313215000, "date": "2020-06-28", "time": "03:00:15", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "PointNetに類似したネットワークを用い点群から三角形メッシュを生成．入力点群から三角形群を出力するネットと，入力三角形群の中から3Dモデルとして妥当な三角形を判定するネットを交互に適用し，メッシュモデルを復元する．\n https://arxiv.org/abs/2005.02138  pic.twitter.com/8JeOljgxXg", "mentions": [], "urls": ["https://arxiv.org/abs/2005.02138"], "photos": ["https://pbs.twimg.com/media/EbkUPnoUEAElg-3.jpg"], "replies_count": 1, "retweets_count": 8, "likes_count": 34, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1277074304786546689", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1276797351001124866, "conversation_id": "1276742451806404608", "created_at": 1593247184000, "date": "2020-06-27", "time": "08:39:44", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Meshlet Priors for 3D Mesh Reconstruction (CVPR2020)\nPaper:  https://arxiv.org/abs/2001.01744 \nCode:  https://github.com/NVlabs/meshlets  pic.twitter.com/9pOqOHCVFd", "mentions": [], "urls": ["https://arxiv.org/abs/2001.01744", "https://github.com/NVlabs/meshlets"], "photos": ["https://pbs.twimg.com/media/EbgYaE-U4AAueo_.jpg"], "replies_count": 0, "retweets_count": 1, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1276797351001124866", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1276742451806404608, "conversation_id": "1276742451806404608", "created_at": 1593234095000, "date": "2020-06-27", "time": "05:01:35", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "スパースまたノイジーな点群からメッシュ生成のため、ローカル幾何形状を表現するMeshletを提案。VAEでMeshletをポーズ不変な潜在空間にエンコード、点群と近いMeshlet(補助メッシュから取出)をデコード、変形の補助メッシュを利用、Meshlet間のグローバルな整合性を強める。 https://youtu.be/glZyJ66ktog ", "mentions": [], "urls": ["https://youtu.be/glZyJ66ktog"], "photos": [], "replies_count": 1, "retweets_count": 7, "likes_count": 27, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1276742451806404608", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1276361313686454272, "conversation_id": "1276361064104341506", "created_at": 1593143225000, "date": "2020-06-26", "time": "03:47:05", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "NRMVS: Non-Rigid Multi-View Stereo (WACV2020)\nVideo:  https://www.youtube.com/watch?v=B4YBWFuYBdE …\nPaper:  http://openaccess.thecvf.com/content_WACV_2020/papers/Innmann_NRMVS_Non-Rigid_Multi-view_Stereo_WACV_2020_paper.pdf … pic.twitter.com/5uHD5WJ9gC", "mentions": [], "urls": ["https://www.youtube.com/watch?v=B4YBWFuYBdE", "http://openaccess.thecvf.com/content_WACV_2020/papers/Innmann_NRMVS_Non-Rigid_Multi-view_Stereo_WACV_2020_paper.pdf"], "photos": ["https://pbs.twimg.com/media/EbaL1U6UcAIdpnz.jpg"], "replies_count": 0, "retweets_count": 2, "likes_count": 8, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1276361313686454272", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1276361064104341506, "conversation_id": "1276361064104341506", "created_at": 1593143165000, "date": "2020-06-26", "time": "03:46:05", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "非剛体変形下での多視点ステレオの提案．まず変形の程度の小さい画像ペアを一組決定し，対象の基本的な3次元構造を復元．さらに，その他の変形を伴う画像群に対してもDeformation graphを利用したJoint optimizationにより，DeformationとDepthの推定を同時に行っている． https://youtu.be/B4YBWFuYBdE ", "mentions": [], "urls": ["https://youtu.be/B4YBWFuYBdE"], "photos": [], "replies_count": 1, "retweets_count": 5, "likes_count": 24, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1276361064104341506", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1276006716606279680, "conversation_id": "1276006512670830593", "created_at": 1593058682000, "date": "2020-06-25", "time": "04:18:02", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "関連研究 https://twitter.com/slam_hub/status/1272001420745535489 …", "mentions": [], "urls": ["https://twitter.com/slam_hub/status/1272001420745535489"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 5, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1276006716606279680", "retweet": false, "quote_url": "https://twitter.com/slam_hub/status/1272001420745535489", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1276006657017839617, "conversation_id": "1276006512670830593", "created_at": 1593058668000, "date": "2020-06-25", "time": "04:17:48", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Kimera: an Open-Source Library for Real-Time Metric-Semantic Localization and Mapping (ICRA 2020)\nVideo:  https://youtu.be/-5XxXRABXJs \nCode:  https://github.com/MIT-SPARK/Kimera …\nPaper:  https://arxiv.org/abs/1910.02490 ", "mentions": [], "urls": ["https://youtu.be/-5XxXRABXJs", "https://github.com/MIT-SPARK/Kimera", "https://arxiv.org/abs/1910.02490"], "photos": [], "replies_count": 1, "retweets_count": 2, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1276006657017839617", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1276006512670830593, "conversation_id": "1276006512670830593", "created_at": 1593058634000, "date": "2020-06-25", "time": "04:17:14", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Visual-Inertial SLAM の Kimera。IMU の on-manifold preintegration と画像の Shi-Tomasi コーナー特徴点で VIO。DBoW2 でループ検出、GTSAM（iSAM2）でグラフ最適化。メッシュ生成と TSDF での復元。画像でセマンティックラベリングして逆投影し、ボクセルをベイズで更新。\n https://arxiv.org/abs/1910.02490  pic.twitter.com/RSnDbyYV23", "mentions": [], "urls": ["https://arxiv.org/abs/1910.02490"], "photos": ["https://pbs.twimg.com/media/EbVJJlXUwAEYf24.jpg"], "replies_count": 1, "retweets_count": 14, "likes_count": 31, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1276006512670830593", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1275630335091281920, "conversation_id": "1275630109311950849", "created_at": 1592968946000, "date": "2020-06-24", "time": "03:22:26", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Atlas: End-to-End 3D Scene Reconstruction from Posed Images (arXiv)\nPaper:  https://arxiv.org/abs/2003.10432 ", "mentions": [], "urls": ["https://arxiv.org/abs/2003.10432"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1275630335091281920", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1275630109311950849, "conversation_id": "1275630109311950849", "created_at": 1592968892000, "date": "2020-06-24", "time": "03:21:32", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "複数視点の2D-CNN出力をVoxelにBack-projetして蓄積し，Voxel mapを3D-CNNに通すことでSemantic情報を含んだMulti-view Stereoを実現．2D-CNNにはResnet50-FPN，3D-CNNはSkip Connectionを持つEncoder-decoderを利用．実時間処理が可能．\n https://arxiv.org/abs/2003.10432  pic.twitter.com/e3e3J3TEua", "mentions": [], "urls": ["https://arxiv.org/abs/2003.10432"], "photos": ["https://pbs.twimg.com/media/EbPyxA_UYAYaXp2.png"], "replies_count": 1, "retweets_count": 9, "likes_count": 39, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1275630109311950849", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1275264014029742080, "conversation_id": "1275262302594293762", "created_at": 1592881608000, "date": "2020-06-23", "time": "03:06:48", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Privacy-Preserving Visual Feature Descriptors through Adversarial Affine Subspace Embedding (arXiv)\nPaper:  https://arxiv.org/abs/2006.06634  pic.twitter.com/3BksIPzqMs", "mentions": [], "urls": ["https://arxiv.org/abs/2006.06634"], "photos": ["https://pbs.twimg.com/media/EbKly60UMAAJ4aO.png"], "replies_count": 0, "retweets_count": 1, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1275264014029742080", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1275262302594293762, "conversation_id": "1275262302594293762", "created_at": 1592881200000, "date": "2020-06-23", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "特徴量を，それ自身を含む部分アフィン空間へ埋め込みことで，識別機能を保ちながらプライバシーアタックへの耐性を大幅に向上．部分空間同士の距離を導入し特徴マッチングを可能とした．元の特徴量と比較して，僅かな識別性能の低下により高いプラバシー保護性能を実現．\n https://arxiv.org/abs/2006.06634  pic.twitter.com/ex4qczr200", "mentions": [], "urls": ["https://arxiv.org/abs/2006.06634"], "photos": ["https://pbs.twimg.com/media/EbH-5qqUMAU4zcQ.png"], "replies_count": 1, "retweets_count": 8, "likes_count": 21, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1275262302594293762", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1274901994814095360, "conversation_id": "1274899915655843840", "created_at": 1592795296000, "date": "2020-06-22", "time": "03:08:16", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": " pic.twitter.com/SZBbuTPgIl", "mentions": [], "urls": [], "photos": ["https://pbs.twimg.com/media/EbFcmujVcAE3RWm.jpg"], "replies_count": 0, "retweets_count": 1, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1274901994814095360", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1274901891248304128, "conversation_id": "1274899915655843840", "created_at": 1592795272000, "date": "2020-06-22", "time": "03:07:52", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Through the Looking Glass: Neural 3D Reconstruction of Transparent Shapes (CVPR2020 Oral)\nPaper:  http://openaccess.thecvf.com/content_CVPR_2020/html/Li_Through_the_Looking_Glass_Neural_3D_Reconstruction_of_Transparent_Shapes_CVPR_2020_paper.html …\nCode: https://github.com/lzqsd/TransparentShapeReconstruction …", "mentions": [], "urls": ["http://openaccess.thecvf.com/content_CVPR_2020/html/Li_Through_the_Looking_Glass_Neural_3D_Reconstruction_of_Transparent_Shapes_CVPR_2020_paper.html", "https://github.com/lzqsd/TransparentShapeReconstruction"], "photos": [], "replies_count": 1, "retweets_count": 2, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1274901891248304128", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1274899915655843840, "conversation_id": "1274899915655843840", "created_at": 1592794801000, "date": "2020-06-22", "time": "03:00:01", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "複数画像からガラスオブジェクトの3D形状を再構築するネットワークを提案．Visual hullで得た荒い形状を元に，各視点で屈折，反射点の法線を推論．環境マップでレンダリングした再投影誤差と，視点間を統合した点群とGTとの損失で学習．高品質な3D復元が可能なことを実証．\n http://openaccess.thecvf.com/content_CVPR_2020/html/Li_Through_the_Looking_Glass_Neural_3D_Reconstruction_of_Transparent_Shapes_CVPR_2020_paper.html … pic.twitter.com/uXXFhuXt98", "mentions": [], "urls": ["http://openaccess.thecvf.com/content_CVPR_2020/html/Li_Through_the_Looking_Glass_Neural_3D_Reconstruction_of_Transparent_Shapes_CVPR_2020_paper.html"], "photos": ["https://pbs.twimg.com/media/EbFP0N1U4AIpIdb.jpg"], "replies_count": 1, "retweets_count": 18, "likes_count": 44, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1274899915655843840", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1274539034413432834, "conversation_id": "1274537524241797121", "created_at": 1592708760000, "date": "2020-06-21", "time": "03:06:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "VPLNet: Deep Single View Normal Estimation With Vanishing Points and Lines (CVPR2020)\nPaper:  http://openaccess.thecvf.com/content_CVPR_2020/html/Wang_VPLNet_Deep_Single_View_Normal_Estimation_With_Vanishing_Points_and_CVPR_2020_paper.html …", "mentions": [], "urls": ["http://openaccess.thecvf.com/content_CVPR_2020/html/Wang_VPLNet_Deep_Single_View_Normal_Estimation_With_Vanishing_Points_and_CVPR_2020_paper.html"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1274539034413432834", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1274537524241797121, "conversation_id": "1274537524241797121", "created_at": 1592708400000, "date": "2020-06-21", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "単一画像での法線推定手法の提案.RGB画像とマンハッタン線マップを入力とし,マンハッタン方向に沿う領域を識別するマップと法線マップをネットワークで回帰,融合する.従来手法より優れた結果を示し未見のデータに対しても推定可能なことを示した.\n http://openaccess.thecvf.com/content_CVPR_2020/html/Wang_VPLNet_Deep_Single_View_Normal_Estimation_With_Vanishing_Points_and_CVPR_2020_paper.html … pic.twitter.com/vRPvFPGMEV", "mentions": [], "urls": ["http://openaccess.thecvf.com/content_CVPR_2020/html/Wang_VPLNet_Deep_Single_View_Normal_Estimation_With_Vanishing_Points_and_CVPR_2020_paper.html"], "photos": ["https://pbs.twimg.com/media/Ea82XPmUMAUDsh2.png", "https://pbs.twimg.com/media/Ea82Y6-UYAAo1YY.jpg", "https://pbs.twimg.com/media/Ea82ZqnUwAAdcoT.png"], "replies_count": 1, "retweets_count": 10, "likes_count": 23, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1274537524241797121", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1274205589107703811, "conversation_id": "1274205587597737985", "created_at": 1592629260000, "date": "2020-06-20", "time": "05:01:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "LiDARsim: Realistic LiDAR Simulation by Leveraging the Real World (CVPR2020)\nPaper:  https://arxiv.org/abs/2006.09348 \nSupp:  http://openaccess.thecvf.com/content_CVPR_2020/html/Manivasagam_LiDARsim_Realistic_LiDAR_Simulation_by_Leveraging_the_Real_World_CVPR_2020_paper.html …", "mentions": [], "urls": ["https://arxiv.org/abs/2006.09348", "http://openaccess.thecvf.com/content_CVPR_2020/html/Manivasagam_LiDARsim_Realistic_LiDAR_Simulation_by_Leveraging_the_Real_World_CVPR_2020_paper.html"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1274205589107703811", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1274205587597737985, "conversation_id": "1274205587597737985", "created_at": 1592629260000, "date": "2020-06-20", "time": "05:01:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Lidarによる実世界データを用いた，従来のCADモデルによる手法よりも多彩で現実感の高い自動運転用シミュレーションを提案．Lidar点群から動的物体や環境マップなどのアセットを作成後，物理レンダリングとDNNでドメインギャップの小さなセンサシミュレーションを行う． https://arxiv.org/abs/2006.09348  pic.twitter.com/nrtVaRw315", "mentions": [], "urls": ["https://arxiv.org/abs/2006.09348"], "photos": ["https://pbs.twimg.com/media/Ea7i_wTU4AAQXtM.jpg"], "replies_count": 1, "retweets_count": 12, "likes_count": 42, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1274205587597737985", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1273816473966800896, "conversation_id": "1273816472230363138", "created_at": 1592536488000, "date": "2020-06-19", "time": "03:14:48", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Revisiting visual-inertial structure from motion for odometry and SLAM initialization (arXiv)\nPaper:  https://arxiv.org/abs/2006.06017 ", "mentions": [], "urls": ["https://arxiv.org/abs/2006.06017"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1273816473966800896", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1273816472230363138, "conversation_id": "1273816472230363138", "created_at": 1592536488000, "date": "2020-06-19", "time": "03:14:48", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "VIO, VI-SLAMにおける状態変数の初期化手法を提案．効率的に不要変数を除去しつつ，3つ以上の3D点の観測を平等に扱う新たな定式化．この線形ソルバはシンプルな構造ながら過去の手法と比較してモーション推定の精度を最大50%向上させ，非線形ソルバの反復回数も削減．\n https://arxiv.org/abs/2006.06017  pic.twitter.com/IYHoycp0k8", "mentions": [], "urls": ["https://arxiv.org/abs/2006.06017"], "photos": ["https://pbs.twimg.com/media/Ea2BLHfU0AA7NHO.png"], "replies_count": 1, "retweets_count": 4, "likes_count": 36, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1273816472230363138", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1273450723481579522, "conversation_id": "1273450361563435008", "created_at": 1592449286000, "date": "2020-06-18", "time": "03:01:26", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "PointAugment: an Auto-Augmentation Framework for Point Cloud Classification (CVPR2020)\nPaper:  https://arxiv.org/abs/2002.10876 \nCode: https://github.com/liruihui/PointAugment/ …", "mentions": [], "urls": ["https://arxiv.org/abs/2002.10876", "https://github.com/liruihui/PointAugment/"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 0, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1273450723481579522", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1273450361563435008, "conversation_id": "1273450361563435008", "created_at": 1592449200000, "date": "2020-06-18", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "End-to-endに学習可能な点群データのAugmentorを提案．入力点群ごとに全体の変形量と個々の点の変位量を出力し，分類器にとってより難しい変換となるよう敵対的に学習する．複数のモデルでランダムな水増しより良い精度を達成．\n https://arxiv.org/abs/2002.10876  pic.twitter.com/Zso2mevGNk", "mentions": [], "urls": ["https://arxiv.org/abs/2002.10876"], "photos": ["https://pbs.twimg.com/media/Eawp7NpUEAAGRP1.jpg"], "replies_count": 1, "retweets_count": 12, "likes_count": 25, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1273450361563435008", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1273119004232683520, "conversation_id": "1273118847114018816", "created_at": 1592370198000, "date": "2020-06-17", "time": "05:03:18", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "LiDAR-based vehicle localization on the satellite image via a neural network (Robotics and Autonomous Systems 2020)\nPaper:  https://www.sciencedirect.com/science/article/pii/S0921889019305202 …\nVideo: https://www.sciencedirect.com/science/article/pii/S0921889019305202#mmc1 …", "mentions": [], "urls": ["https://www.sciencedirect.com/science/article/pii/S0921889019305202", "https://www.sciencedirect.com/science/article/pii/S0921889019305202#mmc1"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1273119004232683520", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1273118847114018816, "conversation_id": "1273118847114018816", "created_at": 1592370161000, "date": "2020-06-17", "time": "05:02:41", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "LIDARスキャンを基に衛星画像上での自己位置推定を行う手法を提案．推定にはパーティクルフィルタを用い，各パーティクル位置の衛星画像とLIDARスキャンの一致度を測るネットワークによって評価する．衛星画像上での遮蔽・陰影に頑強な位置推定が可能であることを示した．\n https://www.sciencedirect.com/science/article/pii/S0921889019305202 … pic.twitter.com/4PelxvyMge", "mentions": [], "urls": ["https://www.sciencedirect.com/science/article/pii/S0921889019305202"], "photos": ["https://pbs.twimg.com/media/EasGz34WsAAWoBV.png"], "replies_count": 1, "retweets_count": 24, "likes_count": 59, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1273118847114018816", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1272743867096301568, "conversation_id": "1272725587359076352", "created_at": 1592280759000, "date": "2020-06-16", "time": "04:12:39", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": " pic.twitter.com/EGCDq1YNgd", "mentions": [], "urls": [], "photos": ["https://pbs.twimg.com/media/Eamxy93UEAAoAWY.jpg"], "replies_count": 0, "retweets_count": 2, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1272743867096301568", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1272726203741290497, "conversation_id": "1272725587359076352", "created_at": 1592276547000, "date": "2020-06-16", "time": "03:02:27", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "MVLidarNet: Real-Time Multi-Class Scene Understanding for Autonomous Driving Using Multiple Views (IROS2020 submission)\nPaper:  https://arxiv.org/abs/2006.05518 \nProject:  https://research.nvidia.com/publication/2020-06_MVLidarNet …", "mentions": [], "urls": ["https://arxiv.org/abs/2006.05518", "https://research.nvidia.com/publication/2020-06_MVLidarNet"], "photos": [], "replies_count": 1, "retweets_count": 1, "likes_count": 6, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1272726203741290497", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1272725587359076352, "conversation_id": "1272725587359076352", "created_at": 1592276400000, "date": "2020-06-16", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "三次元点群の透視投影画像でセマンティックセグメンテーションを行い、分割結果が反応したBEV画像から物体を検出する、シンプルかつ高効率な2-stage検出手法を提案。既存手法と精度の差が大きくない上で、組み込みGPUでもマルチクラス物体検出と道路の分割を150 FPSで実現。 https://youtu.be/2ck5_sToayc ", "mentions": [], "urls": ["https://youtu.be/2ck5_sToayc"], "photos": [], "replies_count": 1, "retweets_count": 8, "likes_count": 23, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1272725587359076352", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1272364047854219265, "conversation_id": "1272363203498930176", "created_at": 1592190203000, "date": "2020-06-15", "time": "03:03:23", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Global visual localization in LiDAR-maps through shared 2D-3D embedding space (ICRA2020)\nVideo:  https://www.facebook.com/iralabdisco/videos/icra2020-submission-global-visual-localization-in-lidar-maps-through-shared-2d-3/371792790436848/ …\nPaper:  https://arxiv.org/abs/1910.04871 ", "mentions": [], "urls": ["https://www.facebook.com/iralabdisco/videos/icra2020-submission-global-visual-localization-in-lidar-maps-through-shared-2d-3/371792790436848/", "https://arxiv.org/abs/1910.04871"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 7, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1272364047854219265", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1272363203498930176, "conversation_id": "1272363203498930176", "created_at": 1592190001000, "date": "2020-06-15", "time": "03:00:01", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "広域なLiDAR地図における単眼カメラの大域位置同定．異種のデータに対するShared embedding spaceを獲得するため，2D-CNNと3D-DNNを一緒に学習する枠組みを提案．同種データ内で完結するSame-Modality lossに加え，異種データ間でCross-Modality lossを用いて学習を行った．\n https://arxiv.org/abs/1910.04871  pic.twitter.com/0Ft0zuZoH8", "mentions": [], "urls": ["https://arxiv.org/abs/1910.04871"], "photos": ["https://pbs.twimg.com/media/EahWh7MU0AELAKE.jpg"], "replies_count": 1, "retweets_count": 10, "likes_count": 34, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1272363203498930176", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1272001581278326785, "conversation_id": "1272001420745535489", "created_at": 1592103784000, "date": "2020-06-14", "time": "03:03:04", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "関連研究\nKimera: an Open-Source Library for Real-Time Metric-Semantic Localization and Mapping (ICRA 2020)\nVideo:  https://youtu.be/-5XxXRABXJs \nCode:  https://github.com/MIT-SPARK/Kimera …\nPaper:  https://arxiv.org/abs/1910.02490 ", "mentions": [], "urls": ["https://youtu.be/-5XxXRABXJs", "https://github.com/MIT-SPARK/Kimera", "https://arxiv.org/abs/1910.02490"], "photos": [], "replies_count": 0, "retweets_count": 3, "likes_count": 10, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1272001581278326785", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1272001518644781056, "conversation_id": "1272001420745535489", "created_at": 1592103769000, "date": "2020-06-14", "time": "03:02:49", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "3D Dynamic Scene Graphs: Actionable Spatial Perception with Places, Objects, and Humans (RSS 2020)\nVideo:  https://youtu.be/SWbofjhyPzI \nPaper:  https://arxiv.org/abs/2002.06289 ", "mentions": [], "urls": ["https://youtu.be/SWbofjhyPzI", "https://arxiv.org/abs/2002.06289"], "photos": [], "replies_count": 1, "retweets_count": 2, "likes_count": 11, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1272001518644781056", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1272001420745535489, "conversation_id": "1272001420745535489", "created_at": 1592103746000, "date": "2020-06-14", "time": "03:02:26", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "建物、部屋、物体などの関係を表すシーングラフを動的環境に拡張し、3D Dynamic Scene Graphs を提案。Visual-Inertial SLAM の Kimera を用いてセマンティックマッピング。さらに移動物体（人のメッシュモデル）をトラッキングして、時空間の物体モデル構造を階層的に表現。\n https://arxiv.org/abs/2002.06289  pic.twitter.com/F5yOdQlh7F", "mentions": [], "urls": ["https://arxiv.org/abs/2002.06289"], "photos": ["https://pbs.twimg.com/media/EacObyPUwAAwARv.jpg"], "replies_count": 1, "retweets_count": 87, "likes_count": 311, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1272001420745535489", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1271652061159907328, "conversation_id": "1271651964275683329", "created_at": 1592020452000, "date": "2020-06-13", "time": "03:54:12", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "OccuSeg: Occupancy-aware 3D Instance Segmentation (CVPR2020)\nPaper:  https://arxiv.org/abs/2003.06537 \nyoutube:  https://youtu.be/co7y6LQ7Kqc  pic.twitter.com/PyloRJb7Z8", "mentions": [], "urls": ["https://arxiv.org/abs/2003.06537", "https://youtu.be/co7y6LQ7Kqc"], "photos": ["https://pbs.twimg.com/media/EaXQzLHVcAEA1ad.jpg"], "replies_count": 0, "retweets_count": 1, "likes_count": 10, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1271652061159907328", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1271651964275683329, "conversation_id": "1271651964275683329", "created_at": 1592020429000, "date": "2020-06-13", "time": "03:53:49", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Voxel ベースの U-Net でsemanticsを推定し，Super-voxel間の類似度を計算して3D instance segmentationを実現．U-Netで各Instanceに対するVoxelの占有数(＝体積)を推定し，適切にSuper-voxelをクラスタリングして Instance を生成．ScanNet Benchmark の現在１位． https://youtu.be/co7y6LQ7Kqc ", "mentions": [], "urls": ["https://youtu.be/co7y6LQ7Kqc"], "photos": [], "replies_count": 1, "retweets_count": 9, "likes_count": 27, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1271651964275683329", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1271280247061676039, "conversation_id": "1271276037117218816", "created_at": 1591931804000, "date": "2020-06-12", "time": "03:16:44", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "3D Photography using Context-aware Layered Depth Inpainting (CVPR2020)\nPaper:  https://arxiv.org/abs/2004.04727 \nProject:  https://shihmengli.github.io/3D-Photo-Inpainting/ …\nCode: https://github.com/vt-vl-lab/3d-photo-inpainting …", "mentions": [], "urls": ["https://arxiv.org/abs/2004.04727", "https://shihmengli.github.io/3D-Photo-Inpainting/", "https://github.com/vt-vl-lab/3d-photo-inpainting"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1271280247061676039", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1271276037117218816, "conversation_id": "1271276037117218816", "created_at": 1591930801000, "date": "2020-06-12", "time": "03:00:01", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "RGB-D単眼画像を入力とし，視点を変えると発生する空白領域をインペインティングするモデルの提案．Depthの断層と層状のDepth表現という着想をベースに，各層で背景を外側へ補完するようにRGB-Dを推定．Mesh表現に変換することで，エッジデバイスでも軽快に動作可能． https://www.youtube.com/watch?v=D0JObXCfxv0 …", "mentions": [], "urls": ["https://www.youtube.com/watch?v=D0JObXCfxv0"], "photos": [], "replies_count": 1, "retweets_count": 4, "likes_count": 22, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1271276037117218816", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1270919475919900674, "conversation_id": "1270913650086178817", "created_at": 1591845790000, "date": "2020-06-11", "time": "03:23:10", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Point2Mesh: A Self-Prior for Deformable Meshes (SIGGRAPH2020)\nProject:\n https://ranahanocka.github.io/point2mesh/ \nCode:\n https://github.com/ranahanocka/Point2Mesh/ …\nYoutube: https://www.youtube.com/watch?v=AySwwJuPqOk&feature=emb_title …", "mentions": [], "urls": ["https://ranahanocka.github.io/point2mesh/", "https://github.com/ranahanocka/Point2Mesh/", "https://www.youtube.com/watch?v=AySwwJuPqOk&feature=emb_title"], "photos": [], "replies_count": 0, "retweets_count": 3, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1270919475919900674", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1270913650086178817, "conversation_id": "1270913650086178817", "created_at": 1591844401000, "date": "2020-06-11", "time": "03:00:01", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "ノイズや欠損を含む点群から高精細な水密メッシュモデルを生成する手法を提案．coarse-to-fineで初期メッシュのエッジの移動量を推定し，入力点群自身と損失を計算して反復的に誤差逆伝搬することでself priorを学習．平滑化仮定では生成できない微細なメッシュも生成可能．\n https://arxiv.org/abs/2005.11084  pic.twitter.com/QLCq7LsaEX", "mentions": [], "urls": ["https://arxiv.org/abs/2005.11084"], "photos": [], "replies_count": 1, "retweets_count": 7, "likes_count": 28, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1270913650086178817", "retweet": false, "quote_url": "", "video": 1, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1270554426483212290, "conversation_id": "1270551260056387585", "created_at": 1591758755000, "date": "2020-06-10", "time": "03:12:35", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": " pic.twitter.com/LECto0vyTT", "mentions": [], "urls": [], "photos": ["https://pbs.twimg.com/media/EaHqfneVAAEJIqZ.jpg"], "replies_count": 0, "retweets_count": 0, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1270554426483212290", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1270554425287774209, "conversation_id": "1270551260056387585", "created_at": 1591758755000, "date": "2020-06-10", "time": "03:12:35", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": " pic.twitter.com/UAT3HsEmrY", "mentions": [], "urls": [], "photos": ["https://pbs.twimg.com/media/EaHqedJU4AEvBDV.jpg"], "replies_count": 1, "retweets_count": 0, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1270554425287774209", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1270554424159563778, "conversation_id": "1270551260056387585", "created_at": 1591758755000, "date": "2020-06-10", "time": "03:12:35", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Novel Object Viewpoint Estimation through Reconstruction Alignment (CVPR 2020)\nProject:  https://mbanani.github.io/novelviewpoints/ …\nCode: https://github.com/mbanani/novelviewpoints …", "mentions": [], "urls": ["https://mbanani.github.io/novelviewpoints/", "https://github.com/mbanani/novelviewpoints"], "photos": [], "replies_count": 1, "retweets_count": 0, "likes_count": 0, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1270554424159563778", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1270551260056387585, "conversation_id": "1270551260056387585", "created_at": 1591758000000, "date": "2020-06-10", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "未知物体を撮影した画像間の相対姿勢の推定. 学習に用いられた物体以外の視点の推定は困難であったが２枚の画像を3D特徴グリッドにマッピングする学習を行い位置を合わせることで相対的な位置を推定する.学習時と大きく異なる物体で推論する際に従来手法より良い精度を示した.\n https://arxiv.org/abs/2006.03586  pic.twitter.com/SktdplZMb1", "mentions": [], "urls": ["https://arxiv.org/abs/2006.03586"], "photos": ["https://pbs.twimg.com/media/EaE9eV9UwAEPo9z.png"], "replies_count": 1, "retweets_count": 3, "likes_count": 21, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1270551260056387585", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1270189473901371400, "conversation_id": "1270188872232660993", "created_at": 1591671744000, "date": "2020-06-09", "time": "03:02:24", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "4D Visualization of Dynamic Events from Unconstrained Multi-View Videos (CVPR2020)\nProject:  http://www.cs.cmu.edu/~aayushb/Open4D/ …\nCode:  https://github.com/aayushbansal/Open4D …\nPaper:  https://arxiv.org/abs/2005.13532 ", "mentions": [], "urls": ["http://www.cs.cmu.edu/~aayushb/Open4D/", "https://github.com/aayushbansal/Open4D", "https://arxiv.org/abs/2005.13532"], "photos": [], "replies_count": 0, "retweets_count": 4, "likes_count": 10, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1270189473901371400", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1270188872232660993, "conversation_id": "1270188872232660993", "created_at": 1591671600000, "date": "2020-06-09", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "複数カメラで撮影された動的イベントに対して，視点と時間を移動可能な4次元時空間可視化を行うシステム．シーン特化のself-supervisedなCNNを用いて静的・動的部分の抽出を行う．SfMによる既存手法で困難であった非ランバート面や，テクスチャレスな領域もキャプチャ可能に． https://youtu.be/sq2hhkHgtb0 ", "mentions": [], "urls": ["https://youtu.be/sq2hhkHgtb0"], "photos": [], "replies_count": 1, "retweets_count": 15, "likes_count": 39, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1270188872232660993", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1269828549495492611, "conversation_id": "1269826483599618049", "created_at": 1591585693000, "date": "2020-06-08", "time": "03:08:13", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "An Efficient Planar Bundle Adjustment Algorithm\nPaper:  https://arxiv.org/abs/2006.00187 ", "mentions": [], "urls": ["https://arxiv.org/abs/2006.00187"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 5, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1269828549495492611", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1269826483599618049, "conversation_id": "1269826483599618049", "created_at": 1591585200000, "date": "2020-06-08", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "点群が平面状に分布する制約を加えたPlaner Bundle Adjustmentを提案．ヤコビアン行列のコンパクトな表現を含む新たな定式化によって精度向上と計算量の削減を両立．評価実験で同問題設定のSOTAと比較して高速，高精度に，そして初期値にロバストなことが示された．\n https://arxiv.org/abs/2006.00187  pic.twitter.com/rVKDwkK3LH", "mentions": [], "urls": ["https://arxiv.org/abs/2006.00187"], "photos": ["https://pbs.twimg.com/media/EZ6nHJqUwAA9OC7.png"], "replies_count": 1, "retweets_count": 4, "likes_count": 35, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1269826483599618049", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1269519363230449665, "conversation_id": "1269519361787613184", "created_at": 1591511977000, "date": "2020-06-07", "time": "06:39:37", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Point-GNN: Graph Neural Network for 3D Object Detection in a Point Cloud (CVPR2020)\nPaper:  https://arxiv.org/abs/2003.01251 \nCode: https://github.com/WeijingShi/Point-GNN …", "mentions": [], "urls": ["https://arxiv.org/abs/2003.01251", "https://github.com/WeijingShi/Point-GNN"], "photos": [], "replies_count": 0, "retweets_count": 4, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1269519363230449665", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1269519361787613184, "conversation_id": "1269519361787613184", "created_at": 1591511977000, "date": "2020-06-07", "time": "06:39:37", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "GNNを用いた三次元点群からの物体検出手法を提案．近傍点を結んだグラフからGNNで特徴抽出し，点ごとに所属する物体クラスとBBOXを推定．最後に重複したBBOXを中央値で統合する．KITTTIデータセットで従来手法を上回る精度を達成．\n https://arxiv.org/abs/2003.01251  pic.twitter.com/Qu1jOIW3xo", "mentions": [], "urls": ["https://arxiv.org/abs/2003.01251"], "photos": ["https://pbs.twimg.com/media/EZ483GVU0AEdfeG.png"], "replies_count": 1, "retweets_count": 6, "likes_count": 44, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1269519361787613184", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1269104524221755395, "conversation_id": "1269104347004022785", "created_at": 1591413072000, "date": "2020-06-06", "time": "03:11:12", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "PoseRBPF: A Rao-Blackwellized Particle Filter for 6D Object Pose Tracking (RSS2019)\nPaper:  https://arxiv.org/abs/1905.09304 \nPresentation:  https://youtu.be/pknL_nyirZ4?t=295 … pic.twitter.com/c5IaCqhBli", "mentions": [], "urls": ["https://arxiv.org/abs/1905.09304", "https://youtu.be/pknL_nyirZ4?t=295"], "photos": ["https://pbs.twimg.com/media/EZzDyfDUcAEfnyk.png"], "replies_count": 0, "retweets_count": 1, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1269104524221755395", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1269104347004022785, "conversation_id": "1269104347004022785", "created_at": 1591413029000, "date": "2020-06-06", "time": "03:10:29", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "6DoF物体姿勢推定のためのRBPFを提案．姿勢分布を分解し，平行移動はサンプリング，回転は物体の各回転に対するEmbeddingを予め計算しておき，パーティクルのEmbeddingをこれと比較することで評価．6DoFを200パーティクル程度でロバストに推定しSOTA精度． https://youtu.be/lE5gjzRKWuA ", "mentions": [], "urls": ["https://youtu.be/lE5gjzRKWuA"], "photos": [], "replies_count": 1, "retweets_count": 5, "likes_count": 25, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1269104347004022785", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1268740773882654720, "conversation_id": "1268739321369989121", "created_at": 1591326347000, "date": "2020-06-05", "time": "03:05:47", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds (ICLR2020)\nProject:  https://ge.in.tum.de/publications/2020-iclr-prantl/ …\nCode:  https://gitlab.com/Prantl/NeuralParticles …\nPaper:  https://openreview.net/forum?id=BJeKh3VYDH … pic.twitter.com/ZcMRH1HQqc", "mentions": [], "urls": ["https://ge.in.tum.de/publications/2020-iclr-prantl/", "https://gitlab.com/Prantl/NeuralParticles", "https://openreview.net/forum?id=BJeKh3VYDH"], "photos": ["https://pbs.twimg.com/media/EZt4zsqU4AEOSMB.jpg"], "replies_count": 0, "retweets_count": 1, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1268740773882654720", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1268739321369989121, "conversation_id": "1268739321369989121", "created_at": 1591326000000, "date": "2020-06-05", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "安定的にフレキシブルな時系列点群の生成手法を提案。既存手法の安定性と多様性の両立し難い問題を改善するため、新たなTemporal Lossを導入、点群から時間的一貫性がある特徴を学習し、変形可能な数が多い点群にたしても有効性を示す。 https://youtu.be/6OoRZrqfSJ4 ", "mentions": [], "urls": ["https://youtu.be/6OoRZrqfSJ4"], "photos": [], "replies_count": 1, "retweets_count": 3, "likes_count": 5, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1268739321369989121", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1268387646407012352, "conversation_id": "1268387507969785856", "created_at": 1591242155000, "date": "2020-06-04", "time": "03:42:35", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "FroDO: From Detections to 3D Objects (CVPR2020)\nProject:  https://research.fb.com/publications/frodo-from-detections-to-3d-objects/ …\nPaper:  https://research.fb.com/wp-content/uploads/2020/05/FroDO-From-Detections-to-3D-Objects.pdf …", "mentions": [], "urls": ["https://research.fb.com/publications/frodo-from-detections-to-3d-objects/", "https://research.fb.com/wp-content/uploads/2020/05/FroDO-From-Detections-to-3D-Objects.pdf"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 5, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1268387646407012352", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1268387507969785856, "conversation_id": "1268387507969785856", "created_at": 1591242122000, "date": "2020-06-04", "time": "03:42:02", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "多視点のRGB画像列に基づく物体の3次元復元手法を提案．Point / Surface による相補的な形状デコードにより形状表現の効率性と記述力を両立させており，より高速な形状復元を実現している．\n https://research.fb.com/wp-content/uploads/2020/05/FroDO-From-Detections-to-3D-Objects.pdf … pic.twitter.com/Y0iFz7omo2", "mentions": [], "urls": ["https://research.fb.com/wp-content/uploads/2020/05/FroDO-From-Detections-to-3D-Objects.pdf"], "photos": ["https://pbs.twimg.com/media/EZo3gFiUcAAONHP.jpg"], "replies_count": 1, "retweets_count": 11, "likes_count": 26, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1268387507969785856", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1268028179727302659, "conversation_id": "1268013854698557440", "created_at": 1591156451000, "date": "2020-06-03", "time": "03:54:11", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "関連研究 https://twitter.com/slam_hub/status/1256059179724271616 …", "mentions": [], "urls": ["https://twitter.com/slam_hub/status/1256059179724271616"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1268028179727302659", "retweet": false, "quote_url": "https://twitter.com/slam_hub/status/1256059179724271616", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1268014480849395712, "conversation_id": "1268013854698557440", "created_at": 1591153185000, "date": "2020-06-03", "time": "02:59:45", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "OverlapNet: Loop Closing for LiDAR-based SLAM (RSS 2020)\nProject:  https://www.ipb.uni-bonn.de/people/xieyuanli-chen/ …\nCode (coming soon):  https://github.com/PRBonn/OverlapNet …\nPaper (pdf):  https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/chen2020rss.pdf … pic.twitter.com/8Yy5coRclW", "mentions": [], "urls": ["https://www.ipb.uni-bonn.de/people/xieyuanli-chen/", "https://github.com/PRBonn/OverlapNet", "https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/chen2020rss.pdf"], "photos": ["https://pbs.twimg.com/media/EZjkY-5U4AEWXYV.jpg"], "replies_count": 1, "retweets_count": 0, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1268014480849395712", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1268013854698557440, "conversation_id": "1268013854698557440", "created_at": 1591153036000, "date": "2020-06-03", "time": "02:57:16", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "SLAM で重要なループ検出を、位置合わせなしで end-to-end に実現。3D-LIDAR の距離画像、法線、受光強度、セマンティクスを入力。2つのスキャンの重複率とヨー角を推定。ループ拘束は SLAM 側で求める。重なりが小さくても適切にループ検出し、SuMa より高精度な地図を構築。 https://youtu.be/YTfliBco6aw ", "mentions": [], "urls": ["https://youtu.be/YTfliBco6aw"], "photos": [], "replies_count": 1, "retweets_count": 11, "likes_count": 45, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1268013854698557440", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1267727696982732802, "conversation_id": "1267727467101315072", "created_at": 1591084810000, "date": "2020-06-02", "time": "08:00:10", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "A Modular Optimization Framework for Localization and Mapping (RSS2019)\nCode:  https://github.com/MOLAorg/mola \nPaper:  http://www.roboticsproceedings.org/rss15/p43.pdf \nPresentation:  https://youtu.be/qwh8hGEJSlA  pic.twitter.com/KLDOehbecC", "mentions": [], "urls": ["https://github.com/MOLAorg/mola", "http://www.roboticsproceedings.org/rss15/p43.pdf", "https://youtu.be/qwh8hGEJSlA"], "photos": ["https://pbs.twimg.com/media/EZffmu9UMAAhiAU.png"], "replies_count": 0, "retweets_count": 3, "likes_count": 8, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1267727696982732802", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1267727467101315072, "conversation_id": "1267727467101315072", "created_at": 1591084756000, "date": "2020-06-02", "time": "07:59:16", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "SLAMを構成要素(入出力, フロント/バックエンド, マップストレージ)に分割し，センサ種類・個数，マッピング方式(global map vs local submaps)，状態空間(SE2/SE3/SE3+vel)などの違いを包括的に扱えるミドルウェア寄りのライブラリを提案． http://youtu.be/Bb92aMBJR44 ", "mentions": [], "urls": ["http://youtu.be/Bb92aMBJR44"], "photos": [], "replies_count": 1, "retweets_count": 18, "likes_count": 34, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1267727467101315072", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1267291184252112896, "conversation_id": "1267289768544460800", "created_at": 1590980738000, "date": "2020-06-01", "time": "03:05:38", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Towards Better Generalization: Joint Depth-Pose Learning without PoseNet (CVPR2020)\nGitHub https://github.com/B1ueber2y/TrianFlow …", "mentions": [], "urls": ["https://github.com/B1ueber2y/TrianFlow"], "photos": [], "replies_count": 0, "retweets_count": 3, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1267291184252112896", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1267289768544460800, "conversation_id": "1267289768544460800", "created_at": 1590980400000, "date": "2020-06-01", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "オプティカルフローを経由して8点法により直接推定した相対姿勢，さらにそこから計算した３次元点を自己教師とすることで，スケールの推定をネットワークから分離し，高い汎化性能とスケールの一貫性を実現．屋内外のデータセットでORB-SLAMや学習ベースの手法を凌駕．\n https://arxiv.org/abs/2004.01314  pic.twitter.com/XU3nSsMtX4", "mentions": [], "urls": ["https://arxiv.org/abs/2004.01314"], "photos": ["https://pbs.twimg.com/media/EZVwVrFUMAIJfoT.png"], "replies_count": 1, "retweets_count": 14, "likes_count": 50, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1267289768544460800", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1266927603731935232, "conversation_id": "1266927379089248256", "created_at": 1590894053000, "date": "2020-05-31", "time": "03:00:53", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "DiPE: Deeper into Photometric Errors for Unsupervised Learning of Depth and Ego-motion from Monocular Videos (IROS 2020)", "mentions": [], "urls": [], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1266927603731935232", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1266927379089248256, "conversation_id": "1266927379089248256", "created_at": 1590894000000, "date": "2020-05-31", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Unsupervised単眼Depth推定で精度を改善する2つの機構の提案．特定のDepth誤りを，フォトメトリックエラーをもとにした外れ値Maskを導入し対処．また，重み付きマルチスケール機構でアーティファクトを除去．簡単に追加できる機構で，他手法よりも高い精度を達成．\n https://arxiv.org/abs/2003.01360  pic.twitter.com/I0JA9KV4Lo", "mentions": [], "urls": ["https://arxiv.org/abs/2003.01360"], "photos": ["https://pbs.twimg.com/media/EZRdRrBVcAckBzq.png"], "replies_count": 1, "retweets_count": 12, "likes_count": 36, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1266927379089248256", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1266567037158977537, "conversation_id": "1266564992805076997", "created_at": 1590808087000, "date": "2020-05-30", "time": "03:08:07", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": " pic.twitter.com/Fs98y7CS2Z", "mentions": [], "urls": [], "photos": ["https://pbs.twimg.com/media/EZO_76lUMAATF-p.jpg"], "replies_count": 0, "retweets_count": 1, "likes_count": 0, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1266567037158977537", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1266567035976212481, "conversation_id": "1266564992805076997", "created_at": 1590808087000, "date": "2020-05-30", "time": "03:08:07", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": " pic.twitter.com/96fNlTaANF", "mentions": [], "urls": [], "photos": ["https://pbs.twimg.com/media/EZO_60XUEAEUP-Q.jpg"], "replies_count": 1, "retweets_count": 1, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1266567035976212481", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1266567034449432577, "conversation_id": "1266564992805076997", "created_at": 1590808087000, "date": "2020-05-30", "time": "03:08:07", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Deep Implicit Volume Compression (CVPR 2020 Oral)\nProject  https://augmentedperception.github.io/deep_volume_compression/ …\nPaper\n https://arxiv.org/abs/2005.08877  pic.twitter.com/AujHzInHUf", "mentions": [], "urls": ["https://augmentedperception.github.io/deep_volume_compression/", "https://arxiv.org/abs/2005.08877"], "photos": ["https://pbs.twimg.com/media/EZO_3FyUcAAH5l_.jpg"], "replies_count": 1, "retweets_count": 1, "likes_count": 5, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1266567034449432577", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1266564992805076997, "conversation_id": "1266564992805076997", "created_at": 1590807600000, "date": "2020-05-30", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Volumetricな表現で使用されるTSDFとそれに対応したテクスチャを圧縮する新しい方法を提案．End-to-Endで訓練されたニューラルネットを用い，トポロジカルなエラーを防ぐためにTSDFの符号を失わずに圧縮する．従来手法より優れた圧縮率と歪みのトレードオフを得た． https://youtu.be/GuLzjnFGDKs ", "mentions": [], "urls": ["https://youtu.be/GuLzjnFGDKs"], "photos": [], "replies_count": 1, "retweets_count": 9, "likes_count": 22, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1266564992805076997", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1266204094286323712, "conversation_id": "1266202604868075520", "created_at": 1590721555000, "date": "2020-05-29", "time": "03:05:55", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "VDO-SLAM: A Visual Dynamic Object-aware SLAM System (submitted to International Journal of Robotics Research)\nCode: https://github.com/halajun/vdo_slam …", "mentions": [], "urls": ["https://github.com/halajun/vdo_slam"], "photos": [], "replies_count": 0, "retweets_count": 4, "likes_count": 6, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1266204094286323712", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1266202604868075520, "conversation_id": "1266202604868075520", "created_at": 1590721200000, "date": "2020-05-29", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "モーションセグメンテーション，動的物体追跡，カメラ姿勢，シーン剛体の姿勢変化や速度の計算を全て行い，実世界の屋外シナリオで実証可能な世界初の動的SLAMシステムを提案．ロバスト性の向上の為，カメラと物体の動きの推定はOptical Flowの改良と合わせて因子グラフ最適化\n https://arxiv.org/abs/2005.11052  pic.twitter.com/esR5t04wPi", "mentions": [], "urls": ["https://arxiv.org/abs/2005.11052"], "photos": ["https://pbs.twimg.com/media/EZJizyPUYAE03aP.jpg"], "replies_count": 2, "retweets_count": 11, "likes_count": 47, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1266202604868075520", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1265849828862386176, "conversation_id": "1265849825678913537", "created_at": 1590637092000, "date": "2020-05-28", "time": "03:38:12", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "関連研究\nSuperPoint: Self-Supervised Interest Point Detection and Description\nPaper:  https://arxiv.org/abs/1712.07629 \nNeural-Guided RANSAC: Learning Where to Sample Model Hypotheses\nPaper:  https://arxiv.org/abs/1905.04132 ", "mentions": [], "urls": ["https://arxiv.org/abs/1712.07629", "https://arxiv.org/abs/1905.04132"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1265849828862386176", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1265849826740064257, "conversation_id": "1265849825678913537", "created_at": 1590637091000, "date": "2020-05-28", "time": "03:38:11", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Reinforced Feature Points:Optimizing Feature Detection and Description for a High-Level Task (CVPR2020 Oral)\nPaper:  https://arxiv.org/abs/1912.00623  pic.twitter.com/bGcxPKEvcA", "mentions": [], "urls": ["https://arxiv.org/abs/1912.00623"], "photos": ["https://pbs.twimg.com/media/EZEzlAbUwAAzZhV.jpg"], "replies_count": 1, "retweets_count": 2, "likes_count": 7, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1265849826740064257", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1265849825678913537, "conversation_id": "1265849825678913537", "created_at": 1590637091000, "date": "2020-05-28", "time": "03:38:11", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "画像の特徴点検出と記述子表現をend-to-endに学習する手法を提案．特徴点マッチングで誤差伝搬できないため，画像間の相対姿勢誤差を負の報酬ににした強化学習で特徴点検出CNNと記述子推定CNNをトレーニングする．学習ベースの局所特徴量抽出器としてSOTAを達成． https://youtu.be/Zttl3eDjNyc ", "mentions": [], "urls": ["https://youtu.be/Zttl3eDjNyc"], "photos": [], "replies_count": 1, "retweets_count": 6, "likes_count": 26, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1265849825678913537", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1265478805390389249, "conversation_id": "1265477828973416448", "created_at": 1590548633000, "date": "2020-05-27", "time": "03:03:53", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "SampleNet: Differentiable Point Cloud Sampling (CVPR2020)\nCode:  https://github.com/itailang/SampleNet …\nPaper:  https://arxiv.org/abs/1912.03663 \nRelated:  https://arxiv.org/abs/1812.01659  pic.twitter.com/grZNpshhiI", "mentions": [], "urls": ["https://github.com/itailang/SampleNet", "https://arxiv.org/abs/1912.03663", "https://arxiv.org/abs/1812.01659"], "photos": ["https://pbs.twimg.com/media/EY_iMYUUwAEQBz-.png"], "replies_count": 0, "retweets_count": 2, "likes_count": 12, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1265478805390389249", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1265477828973416448, "conversation_id": "1265477828973416448", "created_at": 1590548400000, "date": "2020-05-27", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "微分可能な三次元点群のサンプリング手法を提案．NNによって入力点群を簡素化するDovratらの手法を拡張．最近傍サンプリングをk近傍の重み付き和で近似することで，簡素化した点群を基に入力点群をサンプリングするステップを微分可能にした． https://www.youtube.com/watch?v=JHz_ImeI8HE …", "mentions": [], "urls": ["https://www.youtube.com/watch?v=JHz_ImeI8HE"], "photos": [], "replies_count": 1, "retweets_count": 1, "likes_count": 27, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1265477828973416448", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1265120180503363584, "conversation_id": "1265120071728283648", "created_at": 1590463130000, "date": "2020-05-26", "time": "03:18:50", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "G2L-Net: Global to Local Network for Real-time 6D Pose Estimation withEmbedding Vector Features (CVPR2020)\nVideo:  https://youtu.be/a5JWe6mOAEs \nCode:  https://github.com/DC1991/G2L_Net \nPaper:  https://arxiv.org/abs/2003.11089  pic.twitter.com/lghuSEkzDC", "mentions": [], "urls": ["https://youtu.be/a5JWe6mOAEs", "https://github.com/DC1991/G2L_Net", "https://arxiv.org/abs/2003.11089"], "photos": ["https://pbs.twimg.com/media/EY6cF5YVcAExBlu.jpg"], "replies_count": 0, "retweets_count": 0, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1265120180503363584", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1265120071728283648, "conversation_id": "1265120071728283648", "created_at": 1590463104000, "date": "2020-05-26", "time": "03:18:24", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "RGB-D画像から特定の物体の6DoF姿勢を3段階で推定．1.2D物体認識で対象物を含む点群を抽出．2.PointNetを利用し詳細な物体抽出と並進量を推定．3.並進後，回転量をPointNetで推定．回転量推定の学習には，各点に付加した方向ベクトルが真値の方向になるように学習． https://youtu.be/a5JWe6mOAEs ", "mentions": [], "urls": ["https://youtu.be/a5JWe6mOAEs"], "photos": [], "replies_count": 1, "retweets_count": 14, "likes_count": 40, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1265120071728283648", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1264756414146211841, "conversation_id": "1264753052122308615", "created_at": 1590376401000, "date": "2020-05-25", "time": "03:13:21", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "ImVoteNet: Boosting 3D Object Detection in Point Clouds with Image Votes (CVPR2020)\nPaper:  https://arxiv.org/abs/2001.10692 ", "mentions": [], "urls": ["https://arxiv.org/abs/2001.10692"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 7, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1264756414146211841", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1264753052122308615, "conversation_id": "1264753052122308615", "created_at": 1590375600000, "date": "2020-05-25", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "画像からgeometric、semantic、textureのVote特徴を抽出、三次元点群のVote特徴と融合し、3D物体検出の手法を提案。Multi-modalデータ融合を改善するにmulti-towerとgradient blendingの構造を使用し、SUNRGB-Dで既存SOTAより5.7mAPの精度を向上させ、SLAMようなSparse点群に対する有効性も確認。 pic.twitter.com/6zfURbMEPw", "mentions": [], "urls": [], "photos": ["https://pbs.twimg.com/media/EYw3pD7U4AESaXj.jpg"], "replies_count": 1, "retweets_count": 8, "likes_count": 50, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1264753052122308615", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1264390880292507648, "conversation_id": "1264390814454607872", "created_at": 1590289251000, "date": "2020-05-24", "time": "03:00:51", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "PrimiTect: Fast Continuous Hough Voting for Primitive Detection (ICRA2020)\nCode:  https://github.com/c-sommer/primitect …\nPaper:  https://arxiv.org/abs/2005.07457 ", "mentions": [], "urls": ["https://github.com/c-sommer/primitect", "https://arxiv.org/abs/2005.07457"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1264390880292507648", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1264390814454607872, "conversation_id": "1264390814454607872", "created_at": 1590289236000, "date": "2020-05-24", "time": "03:00:36", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "RGB-Dカメラ等で計測された3次元点群における幾何プリミティブ(円柱，円錐，球)の検出．Point Pair Feature に各幾何プリミティブの形状に応じた拘束を導入，またLinear interpolation votingを幾何プリミティブ用に改良し，ハフ変換による低計算量での頑健な検出を実現．\n https://arxiv.org/abs/2005.07457  pic.twitter.com/AylPuLfTAw", "mentions": [], "urls": ["https://arxiv.org/abs/2005.07457"], "photos": ["https://pbs.twimg.com/media/EYwEihiU8AAOrk6.jpg"], "replies_count": 1, "retweets_count": 8, "likes_count": 44, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1264390814454607872", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1264028005694763008, "conversation_id": "1264027851038154753", "created_at": 1590202735000, "date": "2020-05-23", "time": "02:58:55", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Visual Odometry Revisited: What Should Be Learnt? (ICRA 2020)\nVideo:  https://youtu.be/Nl8mFU4SJKY \nCode:  https://github.com/Huangying-Zhan/DF-VO …\nPaper:  https://arxiv.org/abs/1909.09803 ", "mentions": [], "urls": ["https://youtu.be/Nl8mFU4SJKY", "https://github.com/Huangying-Zhan/DF-VO", "https://arxiv.org/abs/1909.09803"], "photos": [], "replies_count": 0, "retweets_count": 3, "likes_count": 11, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1264028005694763008", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1264027851038154753, "conversation_id": "1264027851038154753", "created_at": 1590202698000, "date": "2020-05-23", "time": "02:58:18", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "End-to-End 深層学習の Visual Odometry (VO) の性能は、まだ幾何ベースの手法に及ばない。そこで VO の基礎を再検討し、エピポーラ幾何や PnP と深層学習を組み合わせる手法を提案。スケール整合性のある単眼深度推定とオプティカルフローの2つの CNN を利用。KITTI dataset の評価で従来手法を凌駕。 pic.twitter.com/9C4yJ9i1gv", "mentions": [], "urls": [], "photos": [], "replies_count": 1, "retweets_count": 24, "likes_count": 122, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1264027851038154753", "retweet": false, "quote_url": "", "video": 1, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1263670343962554368, "conversation_id": "1263670128400404480", "created_at": 1590117462000, "date": "2020-05-22", "time": "03:17:42", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Feature-metric Registration: A Fast Semi-supervised Approach for Robust Point Cloud Registration without Correspondences (CVPR2020)\nPaper\n https://arxiv.org/abs/2005.01014 \nCode (中身はまだ未公開？) https://github.com/XiaoshuiHuang/fmr …", "mentions": [], "urls": ["https://arxiv.org/abs/2005.01014", "https://github.com/XiaoshuiHuang/fmr"], "photos": [], "replies_count": 0, "retweets_count": 2, "likes_count": 5, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1263670343962554368", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1263670128400404480, "conversation_id": "1263670128400404480", "created_at": 1590117411000, "date": "2020-05-22", "time": "03:16:51", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "二つの点群について，特徴空間上で並進・回転に対するヤコビアンを数値微分で求めLucus-Kanade法で位置合わせを実行．また点群に対するEncoder-Decorderを構築し特徴をUn-supervisedまたはSemi-supervisedで学習を可能にした．\n https://arxiv.org/abs/2005.01014  pic.twitter.com/JZeCcd11hS", "mentions": [], "urls": ["https://arxiv.org/abs/2005.01014"], "photos": ["https://pbs.twimg.com/media/EYl1RBmU8AIEVoz.png"], "replies_count": 1, "retweets_count": 8, "likes_count": 34, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1263670128400404480", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1263304812994543616, "conversation_id": "1263303500836069376", "created_at": 1590030313000, "date": "2020-05-21", "time": "03:05:13", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Self-Supervised Scene De-occlusion (CVPR2020 Oral)\nParper:  https://arxiv.org/abs/2004.02788 \nProject:  https://xiaohangzhan.github.io/projects/deocclusion/ …", "mentions": [], "urls": ["https://arxiv.org/abs/2004.02788", "https://xiaohangzhan.github.io/projects/deocclusion/"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1263304812994543616", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1263303500836069376, "conversation_id": "1263303500836069376", "created_at": 1590030000000, "date": "2020-05-21", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "self-supervisedに学習可能な，画像のオクルージョン領域を復元するモデルの提案．物体ごとの被オクルージョン領域推定で，増加範囲からオクルージョン関係のグラフを構築．その後推定した領域MaskからRGBを復元．教師あり学習に匹敵するパフォーマンスを達成． https://www.youtube.com/watch?v=xIHCyyaB5gU …", "mentions": [], "urls": ["https://www.youtube.com/watch?v=xIHCyyaB5gU"], "photos": [], "replies_count": 1, "retweets_count": 4, "likes_count": 24, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1263303500836069376", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1262941585102311425, "conversation_id": "1262941112664117248", "created_at": 1589943712000, "date": "2020-05-20", "time": "03:01:52", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Self-Supervised Deep Visual Odometry with Online Adaptation (CVPR 2020 Oral)", "mentions": [], "urls": [], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1262941585102311425", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1262941112664117248, "conversation_id": "1262941112664117248", "created_at": 1589943600000, "date": "2020-05-20", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "自己教師Visual Odometry手法を提案．畳み込みLSTMを利用することで過去の経験を活かして推定をし，未知のシーンにオンラインで適応することが可能．さらにオープンワールドでの環境の変化に対応するために特徴量を揃える手法を提案．既存の手法を大きく上回ることを実験で確認 https://arxiv.org/abs/2005.06136  pic.twitter.com/YMw3oYqEK3", "mentions": [], "urls": ["https://arxiv.org/abs/2005.06136"], "photos": ["https://pbs.twimg.com/media/EYX8UGzUcAErmZZ.png", "https://pbs.twimg.com/media/EYX8UySU0AEph5J.png"], "replies_count": 1, "retweets_count": 8, "likes_count": 30, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1262941112664117248", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1262595838611615744, "conversation_id": "1262595837172973569", "created_at": 1589861280000, "date": "2020-05-19", "time": "04:08:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "End-to-End Pseudo-LiDAR for Image-Based 3D Object Detection (CVPR2020)\nGitHub https://github.com/mileyan/pseudo-LiDAR_e2e …", "mentions": [], "urls": ["https://github.com/mileyan/pseudo-LiDAR_e2e"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1262595838611615744", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1262595837172973569, "conversation_id": "1262595837172973569", "created_at": 1589861280000, "date": "2020-05-19", "time": "04:08:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "画像ベースの深度マップを擬似LiDARに変換し3次元物体検出するというパイプライン全体を，End-to-Endで学習するフレームワーク．既存手法では深度推定と物体検出で別学習していたが，間の表現変化をプーリングと量子化の工夫で微分可能にし実現．PointRCNNと組み合わせでSOTA.\n https://arxiv.org/abs/2004.03080  pic.twitter.com/7TfZbZ079s", "mentions": [], "urls": ["https://arxiv.org/abs/2004.03080"], "photos": ["https://pbs.twimg.com/media/EYWkGGCUcAAMG4l.png"], "replies_count": 1, "retweets_count": 8, "likes_count": 43, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1262595837172973569", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1262224011578101760, "conversation_id": "1262216336865976320", "created_at": 1589772630000, "date": "2020-05-18", "time": "03:30:30", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "SuperGlue: Learning Feature Matching with Graph Neural Networks (CVPR2020 Oral)\nProject:\n https://psarlin.com/superglue/ \nGitHub: https://github.com/magicleap/SuperGluePretrainedNetwork …", "mentions": [], "urls": ["https://psarlin.com/superglue/", "https://github.com/magicleap/SuperGluePretrainedNetwork"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1262224011578101760", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1262216336865976320, "conversation_id": "1262216336865976320", "created_at": 1589770800000, "date": "2020-05-18", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "画像間の局所特徴量をマッチングするGNNを用いたアルゴリズムを提案．視点の大幅な違いにも適用可能．2種類のアテンション機構により画像内，画像間でユニークな特徴量を活用する．GPUでリアルタイム動作し，既存手法と比べ屋内外のシーンで大幅に性能向上． https://arxiv.org/abs/1911.11763  pic.twitter.com/4yuITowWG7", "mentions": [], "urls": ["https://arxiv.org/abs/1911.11763"], "photos": ["https://pbs.twimg.com/media/EYN-WuXUcAABCpb.png"], "replies_count": 1, "retweets_count": 10, "likes_count": 60, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1262216336865976320", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1261854633867177985, "conversation_id": "1261853950791135233", "created_at": 1589684563000, "date": "2020-05-17", "time": "03:02:43", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "PointRend: Image Segmentation as Rendering (arXiv)\nCode:  https://github.com/facebookresearch/detectron2/tree/master/projects/PointRend …", "mentions": [], "urls": ["https://github.com/facebookresearch/detectron2/tree/master/projects/PointRend"], "photos": [], "replies_count": 0, "retweets_count": 2, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1261854633867177985", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1261853950791135233, "conversation_id": "1261853950791135233", "created_at": 1589684400000, "date": "2020-05-17", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "CGレンダリングにヒントを得たセグメンテーションの精緻化モジュールを提案．不確かな点をサンプリングし，MLPで推定し直すことで適応的に物体境界を精緻化．Mask-RCNNやFCNに取り付けることで，少ない計算コストで精度向上．\n https://arxiv.org/abs/1912.08193  pic.twitter.com/KwQ6ASEwyf", "mentions": [], "urls": ["https://arxiv.org/abs/1912.08193"], "photos": ["https://pbs.twimg.com/media/EYL4G6eUEAAfBx6.jpg"], "replies_count": 1, "retweets_count": 5, "likes_count": 36, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1261853950791135233", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1261493010274988033, "conversation_id": "1261492927231975425", "created_at": 1589598345000, "date": "2020-05-16", "time": "03:05:45", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "To Learn or Not to Learn: Visual Localization from Essential Matrices (ICRA2020)\nPaper:  https://arxiv.org/abs/1908.01293 \nCode: https://github.com/GrumpyZhou/visloc-relapose …", "mentions": [], "urls": ["https://arxiv.org/abs/1908.01293", "https://github.com/GrumpyZhou/visloc-relapose"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 6, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1261493010274988033", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1261492927231975425, "conversation_id": "1261492927231975425", "created_at": 1589598325000, "date": "2020-05-16", "time": "03:05:25", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "画像による自己位置推定の精度評価．Data-drivenな手法は，精度面でIndirect法等の従来手法に劣ることが通説となっている．本論文では，特徴量抽出や基礎行列計算等の各フェーズをハンドクラフトからData-drivenまで程度を変え，各組み合わせにおける精度を検証している．\n https://arxiv.org/abs/1908.01293  pic.twitter.com/Rt4IfVGCGK", "mentions": [], "urls": ["https://arxiv.org/abs/1908.01293"], "photos": ["https://pbs.twimg.com/media/EYG5FPiVcAECQWL.jpg"], "replies_count": 1, "retweets_count": 15, "likes_count": 50, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1261492927231975425", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1261133832171819009, "conversation_id": "1261129175722799106", "created_at": 1589512710000, "date": "2020-05-15", "time": "03:18:30", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "RPM-Net: Robust Point Matching using Learned Features (CVPR2020)\nPaper:  https://arxiv.org/abs/2003.13479 \nProject:  https://github.com/yewzijian/RPMNet … pic.twitter.com/P627OysyT8", "mentions": [], "urls": ["https://arxiv.org/abs/2003.13479", "https://github.com/yewzijian/RPMNet"], "photos": ["https://pbs.twimg.com/media/EYByay2U8AEUoY0.jpg"], "replies_count": 0, "retweets_count": 3, "likes_count": 9, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1261133832171819009", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1261129175722799106, "conversation_id": "1261129175722799106", "created_at": 1589511600000, "date": "2020-05-15", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "微分可能なSinkhornレイヤーを使い、hybrid特徴から点と点のソフトな対応を取り、 誤対応やoverlapが少ない点群ペアでも対処できる学習ベースRobust Point Matching点群位置合わせ手法を提案。ModelNet40での実験結果で(rule-&learning-based)既存手法より優れた性能を示す。 https://youtu.be/7hxGmMk4MZ0 ", "mentions": [], "urls": ["https://youtu.be/7hxGmMk4MZ0"], "photos": [], "replies_count": 1, "retweets_count": 8, "likes_count": 20, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1261129175722799106", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1260767355321192451, "conversation_id": "1260767145731821568", "created_at": 1589425336000, "date": "2020-05-14", "time": "03:02:16", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "DOOR-SLAM: Distributed, Online, and Outlier Resilient SLAM for Robotic Teams (RA-L)\npaper:  https://arxiv.org/abs/1909.12198 \nyoutube:  https://www.youtube.com/watch?v=h0bqURQlZGA … pic.twitter.com/TTS8dMExZq", "mentions": [], "urls": ["https://arxiv.org/abs/1909.12198", "https://www.youtube.com/watch?v=h0bqURQlZGA"], "photos": ["https://pbs.twimg.com/media/EX8lMwAU4AE4pk9.png"], "replies_count": 0, "retweets_count": 0, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1260767355321192451", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1260767145731821568, "conversation_id": "1260767145731821568", "created_at": 1589425286000, "date": "2020-05-14", "time": "03:01:26", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "複数ロボット上で走るStereoVOを統合する分散グラフSLAMを提案．ロボット間ループ制約の中から一貫性を保つ最大集合を探す最大クリーク問題を解いて誤検出を除去し，積極的にループ追加を行う方針を採用．大量のループ誤検出を除去し，一貫した地図を生成できることを示した． https://www.youtube.com/watch?v=h0bqURQlZGA …", "mentions": [], "urls": ["https://www.youtube.com/watch?v=h0bqURQlZGA"], "photos": [], "replies_count": 1, "retweets_count": 3, "likes_count": 22, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1260767145731821568", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1260418874496999425, "conversation_id": "1260418715004416009", "created_at": 1589342251000, "date": "2020-05-13", "time": "03:57:31", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Voxgraph: Globally Consistent, Volumetric Mapping using Signed Distance Function Submaps (RA-L 2020)\nCode:  https://github.com/ethz-asl/voxgraph …\nPaper:  https://ieeexplore.ieee.org/document/8903279 … pic.twitter.com/kudUjBy2vy", "mentions": [], "urls": ["https://github.com/ethz-asl/voxgraph", "https://ieeexplore.ieee.org/document/8903279"], "photos": ["https://pbs.twimg.com/media/EX3oQznXYAYcEbG.jpg"], "replies_count": 0, "retweets_count": 1, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1260418874496999425", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1260418715004416009, "conversation_id": "1260418715004416009", "created_at": 1589342213000, "date": "2020-05-13", "time": "03:56:53", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Volumetric な地図表現のグラフベース SLAM 手法．SDF サブマップの集合で環境形状を表現．SDF を利用した位置合わせで隣接拘束を生成してポーズグラフ最適化．対応付け不要なので計算コストが低い．ループ閉じ込みは，外部から DBoW などを利用してループ拘束を与える． https://youtu.be/N9p1_Fkxxro ", "mentions": [], "urls": ["https://youtu.be/N9p1_Fkxxro"], "photos": [], "replies_count": 1, "retweets_count": 6, "likes_count": 25, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1260418715004416009", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1260043416378855424, "conversation_id": "1260043290415489025", "created_at": 1589252735000, "date": "2020-05-12", "time": "03:05:35", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "OmniSLAM: Omnidirectional Localization and Dense Mapping for Wide-baseline Multi-camera Systems (ICRA2020)\nPaper\n https://arxiv.org/abs/2003.08056 \nYoutube\n https://youtu.be/RFhH4j0gzsI \nRelated work: OmniMVS, ROVO\n https://arxiv.org/abs/1908.06257 \n https://arxiv.org/abs/1902.11154 ", "mentions": [], "urls": ["https://arxiv.org/abs/2003.08056", "https://youtu.be/RFhH4j0gzsI", "https://arxiv.org/abs/1908.06257", "https://arxiv.org/abs/1902.11154"], "photos": [], "replies_count": 0, "retweets_count": 3, "likes_count": 6, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1260043416378855424", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1260043290415489025, "conversation_id": "1260043290415489025", "created_at": 1589252705000, "date": "2020-05-12", "time": "03:05:05", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "4つの魚眼カメラを用いてロバストなオドメトリ、全方位のデプス画像生成、密な環境復元を実現．全方位のデプス画像生成にはEnd-to-Endの学習ベースによるOmniMVSを用いて生成．推定した全方位デプス画像をTSDFで統合して密な環境復元を行う．\n https://youtu.be/RFhH4j0gzsI  pic.twitter.com/JfqoF0LKsA", "mentions": [], "urls": ["https://youtu.be/RFhH4j0gzsI"], "photos": ["https://pbs.twimg.com/media/EXySm7iUcAASOh8.png"], "replies_count": 1, "retweets_count": 13, "likes_count": 44, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1260043290415489025", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1259681583398715392, "conversation_id": "1259679622674870272", "created_at": 1589166467000, "date": "2020-05-11", "time": "03:07:47", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Learning to Explore using Active Neural SLAM (ICLR2020)\nPaper\n https://openreview.net/pdf?id=HklXn1BKDH …\nProject\n https://www.cs.cmu.edu/~dchaplot/projects/neural-slam.html …\nCode\n https://github.com/devendrachaplot/Neural-SLAM …\nYoutube https://youtu.be/yl9eQkVdZco ", "mentions": [], "urls": ["https://openreview.net/pdf?id=HklXn1BKDH", "https://www.cs.cmu.edu/~dchaplot/projects/neural-slam.html", "https://github.com/devendrachaplot/Neural-SLAM", "https://youtu.be/yl9eQkVdZco"], "photos": [], "replies_count": 0, "retweets_count": 2, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1259681583398715392", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1259679622674870272, "conversation_id": "1259679622674870272", "created_at": 1589166000000, "date": "2020-05-11", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "画像列から占有格子地図の推定と未知領域探索の行動選択を学習するための強化学習フレームワークを提案．地図と姿勢を推定する\"Neraul SLAM module\"，長期的ゴールを決定する\"Global policy\"，行動を決定する\"Local policy\"の3つの要素で構成．CVPR 2019 Habitat PointGoal Navigation Challenで優勝． pic.twitter.com/onV54zPZDC", "mentions": [], "urls": [], "photos": [], "replies_count": 1, "retweets_count": 16, "likes_count": 63, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1259679622674870272", "retweet": false, "quote_url": "", "video": 1, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1259387726324830208, "conversation_id": "1259387630472409088", "created_at": 1589096406000, "date": "2020-05-10", "time": "07:40:06", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Weakly Supervised Semantic Segmentation in 3D Graph-Structured Point Clouds of Wild Scenes", "mentions": [], "urls": [], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 0, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1259387726324830208", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1259387630472409088, "conversation_id": "1259387630472409088", "created_at": 1589096384000, "date": "2020-05-10", "time": "07:39:44", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "3D点群のクラス推定を2Dのセグメンテーションマップのみを教師として学習するモデルの提案．各点のクラスとvisibilityを推論し，これらで合成した2Dセグメンテーションマップと教師との損失をもとに学習する．複数の物体を含む大規模なシーンでも高い性能を達成． https://arxiv.org/abs/2004.12498v1 … pic.twitter.com/C4Gefp6dFI", "mentions": [], "urls": ["https://arxiv.org/abs/2004.12498v1"], "photos": ["https://pbs.twimg.com/media/EXo-QIDUYAALT0S.jpg"], "replies_count": 1, "retweets_count": 8, "likes_count": 44, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1259387630472409088", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1258592989351260160, "conversation_id": "1258592458109321220", "created_at": 1588906926000, "date": "2020-05-08", "time": "03:02:06", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "GPO: Global Plane Optimization for Fast and Accurate Monocular SLAM Initialization (ICRA2020) pic.twitter.com/isbHbJFRDF", "mentions": [], "urls": [], "photos": ["https://pbs.twimg.com/media/EXdrmJ-U0AA-NVc.png", "https://pbs.twimg.com/media/EXdrm5DU8AAoLNG.png", "https://pbs.twimg.com/media/EXdrnqNUMAAy9fo.png"], "replies_count": 0, "retweets_count": 2, "likes_count": 5, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1258592989351260160", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1258592458109321220, "conversation_id": "1258592458109321220", "created_at": 1588906800000, "date": "2020-05-08", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "単眼SLAMの初期化手法を提案.Homography推定後,Global Plane Optimization (GPO)で最適化しカメラ姿勢と平面の法線を取得.複数フレームの平面情報を組み合わせることで三角測量やHomography分解の計算負荷を減らすことが可能で,精度とリアルタイム性で優れていることを示した.\n https://arxiv.org/abs/2004.12051 ", "mentions": [], "urls": ["https://arxiv.org/abs/2004.12051"], "photos": [], "replies_count": 1, "retweets_count": 6, "likes_count": 33, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1258592458109321220", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1258231159890165762, "conversation_id": "1258230071900475393", "created_at": 1588820659000, "date": "2020-05-07", "time": "03:04:19", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Monocular Camera Localization in Prior LiDAR Maps with 2D-3D Line Correspondences (submitted to IROS2020)\nPaper\n https://arxiv.org/abs/2004.00740 \nGithub\n https://github.com/levenberg/2D-3D-pose-tracking …", "mentions": [], "urls": ["https://arxiv.org/abs/2004.00740", "https://github.com/levenberg/2D-3D-pose-tracking"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1258231159890165762", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1258230071900475393, "conversation_id": "1258230071900475393", "created_at": 1588820400000, "date": "2020-05-07", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "事前のLiDARマップを用いた単眼カメラ定位手法．マップからofflineで3D線を，AFMでビデオからonlineで2D線を検出．VINS-Monoからのカメラ動き予測により，2D-3D線の対応を取得．その2D-3D対応を用いたポーズ最適化により，ループクローズなしで、VIOのドリフトを低減させた． https://youtu.be/H80Bnxm8IPE ", "mentions": [], "urls": ["https://youtu.be/H80Bnxm8IPE"], "photos": [], "replies_count": 1, "retweets_count": 10, "likes_count": 38, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1258230071900475393", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1257868274164887552, "conversation_id": "1257867682533330947", "created_at": 1588734141000, "date": "2020-05-06", "time": "03:02:21", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Learning Feature Descriptors using Camera Pose Supervision\nProject\n https://qianqianwang68.github.io/DescfromPose/ ", "mentions": [], "urls": ["https://qianqianwang68.github.io/DescfromPose/"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1257868274164887552", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1257867682533330947, "conversation_id": "1257867682533330947", "created_at": 1588734000000, "date": "2020-05-06", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "画像間の相対姿勢のみを用いた弱教師あり学習による特徴量抽出手法を提案．中間特徴の相関に基づく微分可能なマッチング層やcourse-to-fine構造のネットワークを用い，エピポーラ幾何の拘束を組み込んだ損失関数で学習を行う．教師あり学習による既存手法の精度を上回った．\n https://arxiv.org/abs/2004.13324  pic.twitter.com/CDPfuoZCOm", "mentions": [], "urls": ["https://arxiv.org/abs/2004.13324"], "photos": ["https://pbs.twimg.com/media/EXQuefGU0AAZ1ZD.jpg"], "replies_count": 1, "retweets_count": 13, "likes_count": 45, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1257867682533330947", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1257506952956936192, "conversation_id": "1257506731942273024", "created_at": 1588647995000, "date": "2020-05-05", "time": "03:06:35", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "PointGroup: Dual-Set Point Grouping for 3D Instance Segmentation (CVPR2020 Oral)\n https://arxiv.org/abs/2004.01658v1 … pic.twitter.com/VZFyGePMms", "mentions": [], "urls": ["https://arxiv.org/abs/2004.01658v1"], "photos": ["https://pbs.twimg.com/media/EXOPyvjVAAA_0Xq.jpg"], "replies_count": 0, "retweets_count": 2, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1257506952956936192", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1257506731942273024, "conversation_id": "1257506731942273024", "created_at": 1588647942000, "date": "2020-05-05", "time": "03:05:42", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "三次元点群のインスタンスセグメンテーション手法の研究．VoxelベースのU-Netで各点のクラスラベルと物体中心へのオフセットを推定．推定された座標について点群をクラスタリングすることで物体候補を生成し，後段のNNでスコアを出力する． https://www.youtube.com/watch?v=HMetye3gmAs …", "mentions": [], "urls": ["https://www.youtube.com/watch?v=HMetye3gmAs"], "photos": [], "replies_count": 1, "retweets_count": 5, "likes_count": 25, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1257506731942273024", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1257146529996869634, "conversation_id": "1257146424707280896", "created_at": 1588562064000, "date": "2020-05-04", "time": "03:14:24", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Real-Time Global Registration for Globally Consistent RGB-D SLAM (IEEE Transactions on Robotics)\nPaper:  https://ieeexplore.ieee.org/document/8606275 …", "mentions": [], "urls": ["https://ieeexplore.ieee.org/document/8606275"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1257146529996869634", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1257146424707280896, "conversation_id": "1257146424707280896", "created_at": 1588562038000, "date": "2020-05-04", "time": "03:13:58", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "リアルタイムでGlobally ConsistentなRGB-D SLAMのため，最適化空間を線形な特徴量部分と非線形な姿勢部分に分解．線形部分を特徴量の二次統計量で表すことで，効率的に計算を行う．処理時間をフレーム数に対してほぼリニアな増加に抑えつつ，SOTA精度を達成．\nPaper:  https://ieeexplore.ieee.org/document/8606275 … pic.twitter.com/2VsW10Ca6T", "mentions": [], "urls": ["https://ieeexplore.ieee.org/document/8606275"], "photos": ["https://pbs.twimg.com/media/EXJH4VjUcAA_hcR.png"], "replies_count": 1, "retweets_count": 3, "likes_count": 26, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1257146424707280896", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1256949008087433216, "conversation_id": "1256726778132828162", "created_at": 1588514971000, "date": "2020-05-03", "time": "14:09:31", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "複数視点の画像を利用しているのは学習時のみで，推定は常に単眼です．（各視点の画像を独立に推定しているのに，動画として整合性が取れているのがポイントです）", "mentions": ["amadeussvx"], "urls": [], "photos": [], "replies_count": 1, "retweets_count": 0, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1256949008087433216", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}, {"user_id": "99270922", "username": "AmadeusSVX"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1256780519343140864, "conversation_id": "1256780519343140864", "created_at": 1588474800000, "date": "2020-05-03", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "三次元点群のOne-Stage物体検出Hybrid Voxel Network (HVNet)手法を提案。Pointwiseでのmulti-scale特徴をHybrid Voxel Feature Extraction(HVFE)で抽出、Voxelwise attention featureにエンコード、Pseudo-Image Featureへデカップル、リアルタイムの31HzでSOTAを達成。\n https://arxiv.org/abs/2003.00186  pic.twitter.com/0yyB3iaOkU", "mentions": [], "urls": ["https://arxiv.org/abs/2003.00186"], "photos": ["https://pbs.twimg.com/media/EW_xwgBUwAAJz8C.jpg"], "replies_count": 0, "retweets_count": 11, "likes_count": 48, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1256780519343140864", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1256466311225290752, "conversation_id": "1256466307647602693", "created_at": 1588399887000, "date": "2020-05-02", "time": "06:11:27", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": " pic.twitter.com/YVJknvUhHF", "mentions": [], "urls": [], "photos": ["https://pbs.twimg.com/media/EW_chyaUcAIKXvq.jpg"], "replies_count": 0, "retweets_count": 0, "likes_count": 0, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1256466311225290752", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1256466309916667904, "conversation_id": "1256466307647602693", "created_at": 1588399886000, "date": "2020-05-02", "time": "06:11:26", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": " pic.twitter.com/fDFNfyDBvc", "mentions": [], "urls": [], "photos": ["https://pbs.twimg.com/media/EW_cb0TVAAAqgk7.jpg"], "replies_count": 1, "retweets_count": 0, "likes_count": 0, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1256466309916667904", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1256466308813602816, "conversation_id": "1256466307647602693", "created_at": 1588399886000, "date": "2020-05-02", "time": "06:11:26", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Consistent Video Depth Estimation (SIGGRAPH 2020)\n@XuanLuo14 \nProject\n https://roxanneluo.github.io/Consistent-Video-Depth-Estimation/ …\nPaper\n https://arxiv.org/abs/2004.15021 ", "mentions": ["xuanluo14"], "urls": ["https://roxanneluo.github.io/Consistent-Video-Depth-Estimation/", "https://arxiv.org/abs/2004.15021"], "photos": [], "replies_count": 1, "retweets_count": 0, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1256466308813602816", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}, {"user_id": "1164375486169923584", "username": "XuanLuo14"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1256466307647602693, "conversation_id": "1256466307647602693", "created_at": 1588399886000, "date": "2020-05-02", "time": "06:11:26", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "単眼デプス推定モデルに対して，SfMで離れた画像ペアを選択し，MVSとOptical Flowの結果から奥行と画像座標の距離を損失としてfine-tuneすることで，動画に対し一貫性のある推定を実現．学習の前処理でMVSの結果からスケールを調整．動物体による誤差の影響でSOTAに近い精度． https://youtu.be/5Tia2oblJAg ", "mentions": [], "urls": ["https://youtu.be/5Tia2oblJAg"], "photos": [], "replies_count": 1, "retweets_count": 10, "likes_count": 45, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1256466307647602693", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1256416317764071424, "conversation_id": "1256416173610041344", "created_at": 1588387967000, "date": "2020-05-02", "time": "02:52:47", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Footprints and Free Space from a Single Color Image (CVPR2020)\nCode:  https://github.com/nianticlabs/footprints …\nPaper:  https://arxiv.org/abs/2004.06376 ", "mentions": [], "urls": ["https://github.com/nianticlabs/footprints", "https://arxiv.org/abs/2004.06376"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1256416317764071424", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1256416173610041344, "conversation_id": "1256416173610041344", "created_at": 1588387933000, "date": "2020-05-02", "time": "02:52:13", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "単眼画像からの自由空間の推定．多視点のステレオ画像から得られた対象環境の幾何情報を単眼画像に集約し学習することで，単一視点からでは不可視な領域に対してもTraversabilityやDepthの評価が可能に．\n https://arxiv.org/abs/2004.06376  pic.twitter.com/7xkhPWGGu8", "mentions": [], "urls": ["https://arxiv.org/abs/2004.06376"], "photos": ["https://pbs.twimg.com/media/EW-vxpMU4AAsxxf.jpg"], "replies_count": 1, "retweets_count": 13, "likes_count": 62, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1256416173610041344", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1256066952667095040, "conversation_id": "1256059179724271616", "created_at": 1588304672000, "date": "2020-05-01", "time": "03:44:32", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Video: https://youtu.be/wuokg7MFZyU ", "mentions": [], "urls": ["https://youtu.be/wuokg7MFZyU"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 0, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1256066952667095040", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1256066878394392578, "conversation_id": "1256059179724271616", "created_at": 1588304655000, "date": "2020-05-01", "time": "03:44:15", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "関連研究2（RangeNet++）\nRangeNet++: Fast and Accurate LiDAR Semantic Segmentation (IROS 2019)\nCode:  https://github.com/PRBonn/lidar-bonnetal …\nPaper:  https://ieeexplore.ieee.org/document/8967762 …", "mentions": [], "urls": ["https://github.com/PRBonn/lidar-bonnetal", "https://ieeexplore.ieee.org/document/8967762"], "photos": [], "replies_count": 1, "retweets_count": 0, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1256066878394392578", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1256066819732828160, "conversation_id": "1256059179724271616", "created_at": 1588304641000, "date": "2020-05-01", "time": "03:44:01", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Video: https://youtu.be/-AEX203rXkE ", "mentions": [], "urls": ["https://youtu.be/-AEX203rXkE"], "photos": [], "replies_count": 1, "retweets_count": 0, "likes_count": 0, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1256066819732828160", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1256066745376239617, "conversation_id": "1256059179724271616", "created_at": 1588304623000, "date": "2020-05-01", "time": "03:43:43", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "関連研究1（SuMa）\nEfficient Surfel-Based SLAM using 3D Laser Range Data in Urban Environments (RSS 2018)\nProject:  http://jbehley.github.io/projects/surfel_mapping/ …\nCode:  https://github.com/jbehley/SuMa \nPaper:  http://www.roboticsproceedings.org/rss14/p16.html ", "mentions": [], "urls": ["http://jbehley.github.io/projects/surfel_mapping/", "https://github.com/jbehley/SuMa", "http://www.roboticsproceedings.org/rss14/p16.html"], "photos": [], "replies_count": 1, "retweets_count": 0, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1256066745376239617", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1256064728041787393, "conversation_id": "1256059179724271616", "created_at": 1588304142000, "date": "2020-05-01", "time": "03:35:42", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Video: https://youtu.be/uo3ZuLuFAzk ", "mentions": [], "urls": ["https://youtu.be/uo3ZuLuFAzk"], "photos": [], "replies_count": 1, "retweets_count": 0, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1256064728041787393", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1256064686878896130, "conversation_id": "1256059179724271616", "created_at": 1588304132000, "date": "2020-05-01", "time": "03:35:32", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "SuMa++: Efficient LiDAR-based Semantic SLAM (IROS 2019)\nCode:  https://github.com/PRBonn/semantic_suma …\nPaper:  https://ieeexplore.ieee.org/document/8967704 …", "mentions": [], "urls": ["https://github.com/PRBonn/semantic_suma", "https://ieeexplore.ieee.org/document/8967704"], "photos": [], "replies_count": 1, "retweets_count": 1, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1256064686878896130", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1256059179724271616, "conversation_id": "1256059179724271616", "created_at": 1588302819000, "date": "2020-05-01", "time": "03:13:39", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "地図を surfel で表現するグラフベース SLAM 手法の SuMa を拡張。3D LIDAR 点群を距離画像に変換し、FCN でセマンティックセグメンテーション。セマンティクスの整合性を重みとする。静止している車は位置合わせに利用される。移動している車が多い KITTI dataset の高速道路でも高精度な推定を実現。 pic.twitter.com/M286GNv7WB", "mentions": [], "urls": [], "photos": ["https://pbs.twimg.com/media/EW5q4e_VcAATkwL.jpg"], "replies_count": 1, "retweets_count": 9, "likes_count": 30, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1256059179724271616", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1255704402347753472, "conversation_id": "1255704202178752513", "created_at": 1588218234000, "date": "2020-04-30", "time": "03:43:54", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Deep Local Shapes: Learning Local SDF Priors for Detailed 3D Reconstruction", "mentions": [], "urls": [], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1255704402347753472", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1255704202178752513, "conversation_id": "1255704202178752513", "created_at": 1588218186000, "date": "2020-04-30", "time": "03:43:06", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Kinect Fusionに利用されているTSDFを学習器に置き換えたDeepSDFを局所適用し，詳細な形状表現を可能にした．DeepSDFは全体を関数近似するのに対し，提案手法はVoxel単位で関数近似．DeepSDFが8日かかった形状復元が，提案手法では1分と大幅に短縮．\n https://arxiv.org/pdf/2003.10983.pdf … pic.twitter.com/Y89OJ9FDXh", "mentions": [], "urls": ["https://arxiv.org/pdf/2003.10983.pdf"], "photos": ["https://pbs.twimg.com/media/EW0oDztVAAIjhWL.jpg"], "replies_count": 1, "retweets_count": 14, "likes_count": 50, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1255704202178752513", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1255361235232620544, "conversation_id": "1255331095656239105", "created_at": 1588136416000, "date": "2020-04-29", "time": "05:00:16", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "第一著者自身の引用論文\n\nHigh-dimensional Convolutional Networks for Geometric Pattern Recognition (CVPR2020)\nPaper:\n http://vladlen.info/papers/HDConvNets.pdf … …\n\nFully Convolutional Geometric Features (ICCV2019)\nPaper:\n https://node1.chrischoy.org/data/publications/fcgf/fcgf.pdf … …\nGithub: https://github.com/chrischoy/FCGF ", "mentions": [], "urls": ["http://vladlen.info/papers/HDConvNets.pdf", "https://node1.chrischoy.org/data/publications/fcgf/fcgf.pdf", "https://github.com/chrischoy/FCGF"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1255361235232620544", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1255345574418755585, "conversation_id": "1255331095656239105", "created_at": 1588132682000, "date": "2020-04-29", "time": "03:58:02", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Deep Global Registration (CVPR2020 Oral)\nProject https://chrischoy.github.io/publication/dgr/ …", "mentions": [], "urls": ["https://chrischoy.github.io/publication/dgr/"], "photos": [], "replies_count": 1, "retweets_count": 1, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1255345574418755585", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1255331095656239105, "conversation_id": "1255331095656239105", "created_at": 1588129230000, "date": "2020-04-29", "time": "03:00:30", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "点群位置合わせの微分可能なフレームワークを提案．6D ConvNetで推定した対応点のInlier確率を重みとし，その重みで微分した勾配をガイドとするProcrustes法により密な対応点を利用した高精度な位置合せが可能．finetuneを追加しEnd-to-endで学習．精度，頑健性，速度でSOTA．\n https://arxiv.org/abs/2004.11540  pic.twitter.com/33W0tiDzCe", "mentions": [], "urls": ["https://arxiv.org/abs/2004.11540"], "photos": [], "replies_count": 1, "retweets_count": 42, "likes_count": 144, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1255331095656239105", "retweet": false, "quote_url": "", "video": 1, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1254971744839852033, "conversation_id": "1254968580136820736", "created_at": 1588043554000, "date": "2020-04-28", "time": "03:12:34", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "SynSin: End-to-end View Synthesis from a Single Image (CVPR2020 Oral)\nProject\n http://www.robots.ox.ac.uk/~ow/synsin.html \nGithub https://github.com/facebookresearch/synsin …", "mentions": [], "urls": ["http://www.robots.ox.ac.uk/~ow/synsin.html", "https://github.com/facebookresearch/synsin"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1254971744839852033", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1254968580136820736, "conversation_id": "1254968580136820736", "created_at": 1588042800000, "date": "2020-04-28", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "任意解像度の単一画像から任意のビューを合成するend-to-endなネットワークの提案．推論したFeatureとDepthを用い点群を構築，微分可能な点群レンダラーとリファインメントネットワークを通すことで欠損のないビューを合成．\n https://arxiv.org/abs/1912.08804  pic.twitter.com/cp2TcgoURr", "mentions": [], "urls": ["https://arxiv.org/abs/1912.08804"], "photos": ["https://pbs.twimg.com/media/EWm4H8TUMAQ2gk5.png"], "replies_count": 1, "retweets_count": 6, "likes_count": 19, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1254968580136820736", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1254608507430526976, "conversation_id": "1254608188801875968", "created_at": 1587956952000, "date": "2020-04-27", "time": "03:09:12", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Online LiDAR-SLAM for Legged Robots with Deep-Learned Loop Closure (ICRA2020)\nProject\n https://ori.ox.ac.uk/lidar-slam/ \nPaper\n https://arxiv.org/abs/2001.10249 ", "mentions": [], "urls": ["https://ori.ox.ac.uk/lidar-slam/", "https://arxiv.org/abs/2001.10249"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1254608507430526976", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1254608188801875968, "conversation_id": "1254608188801875968", "created_at": 1587956876000, "date": "2020-04-27", "time": "03:07:56", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "深層学習を用いた特徴量ベースのループ検出器を組み込んだグラフLiDAR-SLAMシステムを提案．四脚ロボットでも動作するように浅いネットワークを用いておりCPUで推論可能．kd-treeを用いた点群繋ぎ合わせの高速な検証方法を提案．屋内外の産業環境でロバスト性を実証． https://youtu.be/djf7vGtf7CA ", "mentions": [], "urls": ["https://youtu.be/djf7vGtf7CA"], "photos": [], "replies_count": 1, "retweets_count": 7, "likes_count": 36, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1254608188801875968", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1254607258375213056, "conversation_id": "1254607258375213056", "created_at": 1587956654000, "date": "2020-04-27", "time": "03:04:14", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "SLAM-Hubに千葉工大 fuRoの原先生 @ystk_hara が加入されました．千葉周辺にお住まいのSLAM-Hubにご興味のある方は原先生へ気軽にご相談ください．#slamhub", "mentions": ["ystk_hara"], "urls": [], "photos": [], "replies_count": 0, "retweets_count": 3, "likes_count": 19, "hashtags": ["#slamhub"], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1254607258375213056", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}, {"user_id": "1113412223001452545", "username": "ystk_hara"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1254246709997170694, "conversation_id": "1254246604090961920", "created_at": 1587870693000, "date": "2020-04-26", "time": "03:11:33", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "YOLOv4: Optimal Speed and Accuracy of Object Detection\nGithub https://github.com/AlexeyAB/darknet …", "mentions": [], "urls": ["https://github.com/AlexeyAB/darknet"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1254246709997170694", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1254246604090961920, "conversation_id": "1254246604090961920", "created_at": 1587870667000, "date": "2020-04-26", "time": "03:11:07", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "CNNによる高速な物体検出器YOLOの最新版YOLOv4を提案．検出器の学習における，Bag of freebiesやBag of specialsによる効果を検証．バッチ正規化や残差スキップ接続など，モデルやデータセットに関して普遍的で効果のよい手法を用いることで精度を向上させた．\n https://arxiv.org/abs/2004.10934  pic.twitter.com/G3cdiZTGMZ", "mentions": [], "urls": ["https://arxiv.org/abs/2004.10934"], "photos": ["https://pbs.twimg.com/media/EWf6iLgVAAAldSl.png"], "replies_count": 1, "retweets_count": 28, "likes_count": 93, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1254246604090961920", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1253931329139249153, "conversation_id": "1253881416191897600", "created_at": 1587795500000, "date": "2020-04-25", "time": "06:18:20", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Least Squares Optimization: from Theory to Practice\nGithub https://github.com/srrg-sapienza/srrg2_solver …", "mentions": [], "urls": ["https://github.com/srrg-sapienza/srrg2_solver"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 8, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1253931329139249153", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1253881416191897600, "conversation_id": "1253881416191897600", "created_at": 1587783600000, "date": "2020-04-25", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "反復法による最小自乗を解く新たな最適化システムを提案．既存の問題を統一的に解けるようにソルバを設計することで，疎/密，動的/静的な要素にシームレスに対応した．様々な観点で比較評価を行い，提案手法が既存システムに対し同等以上の速度，精度性能を達成した．\n https://arxiv.org/abs/2002.11051  pic.twitter.com/FUqWsYd55A", "mentions": [], "urls": ["https://arxiv.org/abs/2002.11051"], "photos": ["https://pbs.twimg.com/media/EWagb_EUYAEJgO6.jpg"], "replies_count": 1, "retweets_count": 16, "likes_count": 53, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1253881416191897600", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1253519029291094020, "conversation_id": "1253519029291094020", "created_at": 1587697200000, "date": "2020-04-24", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "グラフ描画のアルゴリズムを用いて3D点群を2D画像に投影する手法を提案。投影した画像にU-Netを適用し、3D点群のセグメンテーションでSOTAを達成。階層的クラスタリングで得られた部分点群ごとに投影することで計算コストを削減。\n http://arxiv.org/abs/2003.05593  pic.twitter.com/4Mt0buWYu9", "mentions": [], "urls": ["http://arxiv.org/abs/2003.05593"], "photos": ["https://pbs.twimg.com/media/EWRrybDUcAAkDj3.jpg"], "replies_count": 0, "retweets_count": 8, "likes_count": 19, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1253519029291094020", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1253182647519461378, "conversation_id": "1253182486252670978", "created_at": 1587617000000, "date": "2020-04-23", "time": "04:43:20", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Unsupervised Geometry-Aware Deep LiDAR Odometry (ICRA2020)\nproject: https://sites.google.com/view/deeplo ", "mentions": [], "urls": ["https://sites.google.com/view/deeplo"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 0, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1253182647519461378", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1253182486252670978, "conversation_id": "1253182486252670978", "created_at": 1587616962000, "date": "2020-04-23", "time": "04:42:42", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "2つのLIDARスキャン間の相対姿勢推定をUnsupervisedに学習．全周画像上で特徴量抽出や最終的なICP誤差のロスを定義することで対応付けを避けて学習に適した枠組みとしている．\nvideo: https://www.youtube.com/watch?v=-imRJXq6ZuE … pic.twitter.com/WV2OHJKXzA", "mentions": [], "urls": ["https://www.youtube.com/watch?v=-imRJXq6ZuE"], "photos": ["https://pbs.twimg.com/media/EWQy0LjUwAAj205.png"], "replies_count": 1, "retweets_count": 5, "likes_count": 19, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1253182486252670978", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1252801752589496320, "conversation_id": "1252794252284891136", "created_at": 1587526188000, "date": "2020-04-22", "time": "03:29:48", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "SG-NN: Sparse Generative Neural Networks for Self-Supervised Scene Completion of RGB-D Scans (CVPR2020)\nPaper: \n https://arxiv.org/abs/1912.00036 \nProject:  https://www.3dunderstanding.org/papers/2020/dai2020sgnn/ … pic.twitter.com/uPOIFDJRom", "mentions": [], "urls": ["https://arxiv.org/abs/1912.00036", "https://www.3dunderstanding.org/papers/2020/dai2020sgnn/"], "photos": ["https://pbs.twimg.com/media/EWLYYBEUYAY3X0C.jpg"], "replies_count": 0, "retweets_count": 0, "likes_count": 4, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1252801752589496320", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1252794252284891136, "conversation_id": "1252794252284891136", "created_at": 1587524400000, "date": "2020-04-22", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "ターゲット点群の一部スキャンを削除、更に不完全な点群を入力として、自己教師ありで点群補完を学習させるSG-NNを提案。点群はスパースTSDFで表現、encoder-decoderを使って、見たこともない三次元形状にデコードでき、ターゲット点群より高い分解能点群を補完することが可能 https://youtu.be/rN6D3QmMNuU ", "mentions": [], "urls": ["https://youtu.be/rN6D3QmMNuU"], "photos": [], "replies_count": 1, "retweets_count": 6, "likes_count": 22, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1252794252284891136", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1252430995665518600, "conversation_id": "1252430913985642496", "created_at": 1587437793000, "date": "2020-04-21", "time": "02:56:33", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Efficient Exploration in Constrained Environments with Goal-Oriented Reference Path (arXiv)\n@ohtake_i @kanejaki\nProject: https://keiohta.github.io/publications/2020-03-01_gai_navigation …", "mentions": ["ohtake_i", "kanejaki"], "urls": ["https://keiohta.github.io/publications/2020-03-01_gai_navigation"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1252430995665518600", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}, {"user_id": "370013804", "username": "ohtake_i"}, {"user_id": "107693067", "username": "kanejaki"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1252430913985642496, "conversation_id": "1252430913985642496", "created_at": 1587437773000, "date": "2020-04-21", "time": "02:56:13", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "2D地図を入力とした目的地への経路・行動生成手法の提案．GOSELOと呼ばれる地図表現を介しCNNによるWaypointを生成(教師あり学習)，さらにWaypointに沿うような操作量を生成する層(強化学習)を後段に追加することで安全なナビゲーションを実現している．\n https://arxiv.org/abs/2003.01641  pic.twitter.com/yskq5iMDHZ", "mentions": [], "urls": ["https://arxiv.org/abs/2003.01641"], "photos": ["https://pbs.twimg.com/media/EWGHIEwUYAI5H7e.jpg"], "replies_count": 1, "retweets_count": 17, "likes_count": 80, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1252430913985642496", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1252071221438451713, "conversation_id": "1252071153817903108", "created_at": 1587352016000, "date": "2020-04-20", "time": "03:06:56", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "PerspectiveNet: 3D Object Detection from a Single RGB Image via Perspective Points (NeurIPS2019)", "mentions": [], "urls": [], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 0, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1252071221438451713", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1252071153817903108, "conversation_id": "1252071153817903108", "created_at": 1587352000000, "date": "2020-04-20", "time": "03:06:40", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "RGB画像1枚から物体の3D Bounding Box(3DBB)と6DoF姿勢推定．3DBB投影時のコーナー点位置をテンプレートの重み付け和で表現し，その重みを推定する枠組み．同時に3DBBの3次元位置姿勢を推定し投影点上でのLossを定義し学習する．\n https://arxiv.org/abs/1912.07744  pic.twitter.com/lVKH8vErzB", "mentions": [], "urls": ["https://arxiv.org/abs/1912.07744"], "photos": ["https://pbs.twimg.com/media/EWA_xsTU0AAck4E.jpg"], "replies_count": 1, "retweets_count": 8, "likes_count": 46, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1252071153817903108", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1251712055456829440, "conversation_id": "1251707090277548033", "created_at": 1587266384000, "date": "2020-04-19", "time": "03:19:44", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "NodeSLAM: Neural Object Descriptors for Multi-View Shape Reconstruction\n@SucarEdgar @wkentaro_ @AjdDavison\nProject\n https://edgarsucar.github.io/NodeSLAM/ \nPaper\n https://arxiv.org/abs/2004.04485 ", "mentions": ["sucaredgar", "wkentaro_", "ajddavison"], "urls": ["https://edgarsucar.github.io/NodeSLAM/", "https://arxiv.org/abs/2004.04485"], "photos": [], "replies_count": 0, "retweets_count": 2, "likes_count": 5, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1251712055456829440", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}, {"user_id": "858493718952804352", "username": "SucarEdgar"}, {"user_id": "782291244", "username": "wkentaro_"}, {"user_id": "1446792746", "username": "AjdDavison"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1251707090277548033, "conversation_id": "1251707090277548033", "created_at": 1587265200000, "date": "2020-04-19", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "VAEを用いて学習した各物体カテゴリの3D形状特徴量を，トラッキングしながらカメラ姿勢と同時に最適化することで，単一あるいは複数視点のRGB-D画像から，オクルージョンがあっても欠損がない物体の高精度な3D形状を復元する手法を提案． https://www.youtube.com/watch?time_continue=279&v=zPzMtXU-0JE&feature=emb_logo …", "mentions": [], "urls": ["https://www.youtube.com/watch?time_continue=279&v=zPzMtXU-0JE&feature=emb_logo"], "photos": [], "replies_count": 1, "retweets_count": 14, "likes_count": 39, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1251707090277548033", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1251407484897554432, "conversation_id": "1251344702227353600", "created_at": 1587193769000, "date": "2020-04-18", "time": "07:09:29", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Redesigning SLAM for Arbitrary Multi-Camera Systems (ICRA2020)\n https://arxiv.org/abs/2003.02014  pic.twitter.com/eMBMAKlj8e", "mentions": [], "urls": ["https://arxiv.org/abs/2003.02014"], "photos": ["https://pbs.twimg.com/media/EV3kby_UEAAn3ca.png"], "replies_count": 0, "retweets_count": 0, "likes_count": 2, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1251407484897554432", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1251344702227353600, "conversation_id": "1251344702227353600", "created_at": 1587178800000, "date": "2020-04-18", "time": "03:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "既存のVisual SLAM手法を任意の複数カメラシステムに拡張する手法を提案．適応的な初期化，センサに依存しないキーフレーム選択，voxelベースのマップ管理法を用いることで，精度を保ちセンサ固有の改良なしでの動作を実現. https://www.youtube.com/watch?v=JGL4H93BiNw …", "mentions": [], "urls": ["https://www.youtube.com/watch?v=JGL4H93BiNw"], "photos": [], "replies_count": 1, "retweets_count": 13, "likes_count": 49, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1251344702227353600", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1250976017079922688, "conversation_id": "1250976017079922688", "created_at": 1587090899000, "date": "2020-04-17", "time": "02:34:59", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "ワイドベースラインカメラで撮影した6枚の画像から高品質な幾何形状とSVBRDFを復元する学習ベースの手法を提案．各画像ごとに拡散・鏡面アルベド，法線，鏡面粗さをネットワークで推定し，推定結果を融合して幾何形状とSVBRDF得る．従来難しかった疎な画像からの復元に成功．\n https://arxiv.org/abs/2003.12642  pic.twitter.com/Qn5OoQkR0s", "mentions": [], "urls": ["https://arxiv.org/abs/2003.12642"], "photos": ["https://pbs.twimg.com/media/EVxb1NiU4AEJwkl.jpg"], "replies_count": 0, "retweets_count": 23, "likes_count": 48, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1250976017079922688", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1250609125467189249, "conversation_id": "1250589729210449920", "created_at": 1587003425000, "date": "2020-04-16", "time": "02:17:05", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "ClusterVO: Clustering Moving Instances and Estimating Visual Odometry for Self and Surroundings (CVPR2020)\n https://arxiv.org/abs/2003.12980  pic.twitter.com/TD0uMjecFV", "mentions": [], "urls": ["https://arxiv.org/abs/2003.12980"], "photos": ["https://pbs.twimg.com/media/EVsOUMIU0AE-bYa.jpg"], "replies_count": 0, "retweets_count": 1, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1250609125467189249", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1250589729210449920, "conversation_id": "1250589729210449920", "created_at": 1586998800000, "date": "2020-04-16", "time": "01:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "ステレオカメラを用いて，物体上の特徴点のクラスター化と，自身と物体の動きの推定を同時に行うシステムを提案．クラスター化は，物体検出による特徴点のクラスラベルを用いて，3次元位置も考慮したCRFにより実装．シーンに依存せず，オンラインでの動作を可能にした． https://www.youtube.com/watch?v=paK-WCQpX-Y&feature=youtu.be …", "mentions": [], "urls": ["https://www.youtube.com/watch?v=paK-WCQpX-Y&feature=youtu.be"], "photos": [], "replies_count": 1, "retweets_count": 9, "likes_count": 17, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1250589729210449920", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1250246481644122112, "conversation_id": "1250227339776217088", "created_at": 1586916964000, "date": "2020-04-15", "time": "02:16:04", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "DeepFactors: Real-Time Probabilistic Dense Monocular SLAM (RA-L)\n https://arxiv.org/abs/2001.05049  pic.twitter.com/raqAYPgSje", "mentions": [], "urls": ["https://arxiv.org/abs/2001.05049"], "photos": ["https://pbs.twimg.com/media/EVnEelhU0AA3cwA.jpg"], "replies_count": 0, "retweets_count": 1, "likes_count": 6, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1250246481644122112", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1250227339776217088, "conversation_id": "1250227339776217088", "created_at": 1586912400000, "date": "2020-04-15", "time": "01:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "CodeSLAMをベースにした新たな深層学習ベースのVisual SLAMシステムを提案．既存のコードによるコンパクトなデプスマップ表現に加え，損失関数の改善，ループクロージングと全体最適化の追加により，精度とロバストを向上．さらにリアルタイム動作を実現した． https://www.youtube.com/watch?v=htnRuGKZmZw …", "mentions": [], "urls": ["https://www.youtube.com/watch?v=htnRuGKZmZw"], "photos": [], "replies_count": 1, "retweets_count": 5, "likes_count": 21, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1250227339776217088", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1249879286372118528, "conversation_id": "1249864951092506624", "created_at": 1586829418000, "date": "2020-04-14", "time": "01:56:58", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Github: https://github.com/QingyongHu/RandLA-Net …", "mentions": [], "urls": ["https://github.com/QingyongHu/RandLA-Net"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 0, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1249879286372118528", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1249879119694680064, "conversation_id": "1249864951092506624", "created_at": 1586829378000, "date": "2020-04-14", "time": "01:56:18", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "RandLA-Net: Efficient Semantic Segmentation of Large-Scale Point Clouds (CVPR2020)\nVideo: https://www.youtube.com/watch?v=Ar3eY_lwzMk&feature=youtu.be …", "mentions": [], "urls": ["https://www.youtube.com/watch?v=Ar3eY_lwzMk&feature=youtu.be"], "photos": [], "replies_count": 1, "retweets_count": 1, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1249879119694680064", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1249864951092506624, "conversation_id": "1249864951092506624", "created_at": 1586826000000, "date": "2020-04-14", "time": "01:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "点数が百万を超える大規模三次元点群のセグメンテーションにおいては、従来の高コストな点群サンプリング手法よりもランダムサンプリングが有効であることを示した．KNNとアテンションを用いて積極的に受容野を拡大することで、サンプリングによる点群の欠損に対処．\n https://arxiv.org/abs/1911.11236  pic.twitter.com/xjpFO7WABl", "mentions": [], "urls": ["https://arxiv.org/abs/1911.11236"], "photos": ["https://pbs.twimg.com/media/EVfbCzoU4AEISU9.png"], "replies_count": 1, "retweets_count": 9, "likes_count": 24, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1249864951092506624", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1249534277026373636, "conversation_id": "1249517662847283201", "created_at": 1586747161000, "date": "2020-04-13", "time": "03:06:01", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "R-LINS: A Robocentric Lidar-Inertial State Estimator for Robust and Efficient Navigation (ICRA2020)\nvideo: https://www.youtube.com/watch?v=Nmr1blC09qw …", "mentions": [], "urls": ["https://www.youtube.com/watch?v=Nmr1blC09qw"], "photos": [], "replies_count": 0, "retweets_count": 0, "likes_count": 1, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1249534277026373636", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1249517662847283201, "conversation_id": "1249517662847283201", "created_at": 1586743200000, "date": "2020-04-13", "time": "02:00:00", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "LIDAR-IMUのオドメトリ推定手法．Error State Kalman Filter上でTight-couplingに最適化を行うことで，従来のグラフベース手法と近い精度を維持しつつ大幅に処理速度を向上させた．\npaper: https://arxiv.org/abs/1907.02233  pic.twitter.com/IQ4YAzhL8q", "mentions": [], "urls": ["https://arxiv.org/abs/1907.02233"], "photos": ["https://pbs.twimg.com/media/EVaW8PaUMAAm7RO.jpg"], "replies_count": 1, "retweets_count": 6, "likes_count": 38, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1249517662847283201", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1249155400122994688, "conversation_id": "1249155400122994688", "created_at": 1586656830000, "date": "2020-04-12", "time": "02:00:30", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Object Levelより細かく，新たな形状表現Local Implicit Grid (LIG)を提案．AutoencoderでPartの形状をlatent vectorにエンコード，入力点群と復元ロス最小なlatent vectorを最適化，LIGでの内挿により形状にデコード、機械学習で点群からScene Levelの三次元形状復元が可能． https://youtu.be/XCyl1-vxfII ", "mentions": [], "urls": ["https://youtu.be/XCyl1-vxfII"], "photos": [], "replies_count": 1, "retweets_count": 2, "likes_count": 8, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1249155400122994688", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1248796509975359488, "conversation_id": "1248796223961624576", "created_at": 1586571264000, "date": "2020-04-11", "time": "02:14:24", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "EPOS: Estimating 6D Pose of Objects with Symmetries (CVPR2020)\nProject:  http://cmp.felk.cvut.cz/epos/ ", "mentions": [], "urls": ["http://cmp.felk.cvut.cz/epos/"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1248796509975359488", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1248796223961624576, "conversation_id": "1248796223961624576", "created_at": 1586571195000, "date": "2020-04-11", "time": "02:13:15", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "RGB画像における物体の6DoF姿勢推定．Surface fragmentによる3次元モデル表現を介し，物体のPoseを各PixelがどのようなインスタンスやSurface fragmentに対応しうるかを学習．得られた多対多な2D-3D対応をPnP-RANSACによりロバスト化．\n https://arxiv.org/pdf/2004.00605.pdf … pic.twitter.com/Qn2Etv1Nst", "mentions": [], "urls": ["https://arxiv.org/pdf/2004.00605.pdf"], "photos": ["https://pbs.twimg.com/media/EVSdYxHU0AIFkpg.jpg"], "replies_count": 1, "retweets_count": 5, "likes_count": 23, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1248796223961624576", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1248466071301935110, "conversation_id": "1248436573865041920", "created_at": 1586492481000, "date": "2020-04-10", "time": "04:21:21", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Beyond Photometric Consistency: Gradient-based Dissimilarity for Improving Visual Odometry and Stereo Matching [ICRA2020]\n\nVideo:  https://www.ais.uni-bonn.de/videos/ICRA_2020_Gradient_Dissimilarity/ …", "mentions": [], "urls": ["https://www.ais.uni-bonn.de/videos/ICRA_2020_Gradient_Dissimilarity/"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 3, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1248466071301935110", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1248436573865041920, "conversation_id": "1248436573865041920", "created_at": 1586485448000, "date": "2020-04-10", "time": "02:24:08", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "画像の位置合わせに必要なエラーについて，輝度差に代わる新たなメトリックSGFを提案．SGFは勾配画像のコントラストを局所的に正規化し，勾配方向の内積を利用．DSOにSGFを適用したところ精度が改善．\n https://arxiv.org/pdf/2004.04090.pdf … pic.twitter.com/HL3hkOLo61", "mentions": [], "urls": ["https://arxiv.org/pdf/2004.04090.pdf"], "photos": ["https://pbs.twimg.com/media/EVNWXyhUUAAYvJo.png"], "replies_count": 1, "retweets_count": 4, "likes_count": 20, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1248436573865041920", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1248203546060681217, "conversation_id": "1248070308080177152", "created_at": 1586429890000, "date": "2020-04-09", "time": "10:58:10", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Spatial Hashing (メモリ効率の良いボクセル表現)に関する引用文献\nReal-time 3D Reconstruction at Scale using Voxel Hashing\n https://niessnerlab.org/papers/2013/4hashing/niessner2013hashing.pdf …\nOptimized Spatial Hashing for Collision Detection of Deformable Objects\n https://matthias-research.github.io/pages/publications/tetraederCollision.pdf …", "mentions": [], "urls": ["https://niessnerlab.org/papers/2013/4hashing/niessner2013hashing.pdf", "https://matthias-research.github.io/pages/publications/tetraederCollision.pdf"], "photos": [], "replies_count": 0, "retweets_count": 1, "likes_count": 7, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1248203546060681217", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1248070308080177152, "conversation_id": "1248070308080177152", "created_at": 1586398124000, "date": "2020-04-09", "time": "02:08:44", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "Visual SLAMで用いられる従来のキーフレーム表現（covisibility graph）では，3D点の遮蔽関係を記述できないため，ボクセルハッシングと視錐台表現を用いたレイキャスティングにより，高速かつ省メモリに幾何的関係性の記述を可能とした．\n https://arxiv.org/abs/2003.02247  pic.twitter.com/MMeABTUKVP", "mentions": [], "urls": ["https://arxiv.org/abs/2003.02247"], "photos": ["https://pbs.twimg.com/media/EVII8izVAAE-WVi.png"], "replies_count": 1, "retweets_count": 3, "likes_count": 30, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1248070308080177152", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
{"id": 1247356052657455105, "conversation_id": "1247356052657455105", "created_at": 1586227832000, "date": "2020-04-07", "time": "02:50:32", "timezone": "UTC", "user_id": 1244129482132209664, "username": "slam_hub", "name": "SLAM-Hub", "place": "", "tweet": "R&Dコミュニティ「SLAM-Hub」を立ち上げました！\n一緒に研究開発してくれるメンバーを募集しています． https://slamhub.xslam.org/?0 ", "mentions": [], "urls": ["https://slamhub.xslam.org/?0"], "photos": [], "replies_count": 0, "retweets_count": 66, "likes_count": 185, "hashtags": [], "cashtags": [], "link": "https://twitter.com/slam_hub/status/1247356052657455105", "retweet": false, "quote_url": "", "video": 0, "near": "", "geo": "", "source": "", "user_rt_id": "", "user_rt": "", "retweet_id": "", "reply_to": [{"user_id": "1244129482132209664", "username": "slam_hub"}], "retweet_date": "", "translate": "", "trans_src": "", "trans_dest": ""}
